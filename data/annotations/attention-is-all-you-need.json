[
  {
    "id": "199a7c82",
    "type": "note",
    "selectedText": "embeddings are offset by one position, ensures that the predictions for position i can depend only on the known outputs at positions less than i.\n\n3.2 Attention\nAn attention function can be described as mapping a query and a set of key-value pairs to an output, where the query, keys, values, and output are all vectors. The output is computed as a wei",
    "note": "kkk",
    "color": "var(--note-highlight)",
    "replacementText": "",
    "anchorSelector": "",
    "anchorOffset": 0,
    "createdAt": "2026-02-27T01:26:44.575Z",
    "updatedAt": "2026-02-27T01:26:44.575Z"
  }
]
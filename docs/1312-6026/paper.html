<h1>How to Construct Deep Recurrent Neural Networks</h1>

<p class="authors"></p>

<h2>Abstract</h2>
<p>In this paper, we explore different ways to extend a recurrent
    neural network (RNN) to a \textit{deep} RNN. We start by
    arguing that the concept of depth in an RNN is not as clear
    as it is in feedforward neural networks.  By carefully
    analyzing and understanding the architecture of an RNN,
    however, we find three points of an RNN which may be made
    deeper; (1) input-to-hidden function, (2) hidden-to-hidden
    transition and (3) hidden-to-output function. Based on this
    observation, we propose two novel architectures of a deep RNN
    which are orthogonal to an earlier attempt of stacking
    multiple recurrent layers to build a deep RNN
    \citep{Schmidhuber1992,ElHihi+Bengio-nips8}.  We provide an alternative
    interpretation of these deep RNNs using a novel framework
    based on neural operators. The proposed deep RNNs are
    empirically evaluated on the tasks of polyphonic music
    prediction and language modeling. The experimental result
    supports our claim that the proposed deep RNNs benefit from
    the depth and outperform the conventional, shallow RNNs.</p>

<hr>

<h2>1. Introduction</h2>

<p>Recurrent neural networks~\citep[RNN, see, e.g.,][]{Rumelhart86b} have recently
become a popular choice for modeling variable-length sequences.  RNNs have been
successfully used for various task such as language modeling~\citep[see,
e.g.,][]{Graves2013,Pascanu+al-ICML2013-small,Mikolov-thesis-2012,Sutskever2011},
learning word embeddings~\citep[see, e.g.,][]{Mikolov2013}, online handwritten
recognition~<sup class="ref-badge" data-ref="17" data-title="Schmidhuber, J. (2009).">17</sup> and speech recognition~<sup class="ref-badge" data-ref="18" data-title="Speech recognition with deep recurrent neural networks.">18</sup>.</p>

<p>In this work, we explore *deep* extensions of the basic RNN. Depth for
feedforward models can lead to more expressive models~<sup class="ref-badge" data-ref="41" data-title="On the number of response regions of deep feed forward networks with">41</sup>, and
we believe the same should hold for recurrent models.  We claim that, unlike in
the case of feedforward neural networks, the *depth* of an RNN is
ambiguous.  In one sense, if we consider the existence of a composition of
several nonlinear computational layers in a neural network being deep, RNNs are
already deep, since any RNN can be expressed as a composition of multiple
nonlinear layers when unfolded in time.</p>

<sup class="ref-badge" data-ref="45" data-title="Learning complex, extended sequences using the principle of history">45</sup>[ElHihi+Bengio-nips8] earlier proposed another way of building a deep RNN by
stacking multiple recurrent hidden states on top of each other. This approach
potentially allows the hidden state at each level to operate at different
timescale~\citep[see, e.g.,][]{Hermans2013}.  Nonetheless, we notice that there
are some other aspects of the model that may still be considered
*shallow*. For instance, the transition between two consecutive hidden
states at a single level is shallow, when viewed separately.This has
implications on what kind of transitions this model can represent as discussed
in Section~<a href="#sec:deep_hid_to_hid" class="cross-ref">Section 4</a>.

<p>Based on this observation, in this paper, we investigate possible approaches to
extending an RNN into a deep RNN. We begin by studying which parts of an RNN
may be considered shallow.  Then, for each shallow part, we propose an
alternative *deeper* design, which leads to a number of deeper variants
of an RNN. The proposed deeper variants are then empirically evaluated on two
sequence modeling tasks.</p>

<p>The layout of the paper is as follows.  In Section~<a href="#sec:rnn" class="cross-ref">Section 1</a> we briefly
introduce the concept of an RNN. In Section~<a href="#sec:drnn" class="cross-ref">Section 2</a> we explore different
concepts of *depth* in RNNs.  In particular, in
Section~<a href="#sec:dt_rnn" class="cross-ref">Section 5</a>--<a href="#sec:dot_rnn" class="cross-ref">Section 6</a> we propose two novel variants of
deep RNNs and evaluate them empirically in Section~<a href="#sec:experiments" class="cross-ref">Section 7</a> on two
tasks: polyphonic music prediction~[Boulanger+al-ICML2012-small] and
language modeling.  Finally we discuss the shortcomings and advantages of the
proposed models in Section~<a href="#sec:final" class="cross-ref">Section 8</a>.</p>

<hr>

<h2>2. Recurrent Neural Networks</h2>

<span id="sec:rnn" class="label-anchor"></span>

<p>A recurrent neural network (RNN) is a neural network that simulates a
discrete-time dynamical system that has an input <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">x</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">\vx_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5944em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathbf">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span>, an output <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">y</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">\vy_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6389em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathbf" style="margin-right:0.01597em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:-0.016em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span> and
a hidden state <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">h</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">\vh_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathbf">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span>.  In our notation the subscript <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi></mrow><annotation encoding="application/x-tex">t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6151em;"></span><span class="mord mathnormal">t</span></span></span></span></span> represents time.
The dynamical system is defined by</p>

<div class="math-display"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi mathvariant="bold">h</mi><mi>t</mi></msub><mo>=</mo><msub><mi>f</mi><mi>h</mi></msub><mo stretchy="false">(</mo><msub><mi mathvariant="bold">x</mi><mi>t</mi></msub><mo separator="true">,</mo><msub><mi mathvariant="bold">h</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">
    \vh_t  = f_h(\vx_t, \vh_{t-1})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathbf">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.1076em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">h</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathbf">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathbf">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2083em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></div>
<div class="math-display"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi mathvariant="bold">y</mi><mi>t</mi></msub><mo>=</mo><msub><mi>f</mi><mi>o</mi></msub><mo stretchy="false">(</mo><msub><mi mathvariant="bold">h</mi><mi>t</mi></msub><mo stretchy="false">)</mo><mo separator="true">,</mo></mrow><annotation encoding="application/x-tex">
    \vy_t  = f_o(\vh_t),</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6389em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathbf" style="margin-right:0.01597em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:-0.016em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.1076em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">o</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathbf">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mpunct">,</span></span></span></span></span></div>

<p>where <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>f</mi><mi>h</mi></msub></mrow><annotation encoding="application/x-tex">f_h</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.1076em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">h</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span> and <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>f</mi><mi>o</mi></msub></mrow><annotation encoding="application/x-tex">f_o</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.1076em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">o</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span> are a state transition function and an
output function, respectively. Each function is parameterized by
a set of parameters; <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold-italic">θ</mi><mi>h</mi></msub></mrow><annotation encoding="application/x-tex">\TT_h</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord"><span class="mord"><span class="mord"><span class="mord boldsymbol" style="margin-right:0.03194em;">θ</span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">h</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span> and <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold-italic">θ</mi><mi>o</mi></msub></mrow><annotation encoding="application/x-tex">\TT_o</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord"><span class="mord"><span class="mord"><span class="mord boldsymbol" style="margin-right:0.03194em;">θ</span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">o</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span>.</p>

<p>Given a set of <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span></span></span></span></span> training sequences 
$D=\left\{ \left(
    (\vx_1^{(n)}, \vy_1^{(n)} ), \dots, (\vx_{T_n}^{(n)},
    \vy_{T_n}^{(n)}) \right)\right\}_{n=1}^N$, 
the parameters of an RNN can be estimated by minimizing the
following cost function:</p>

<div class="math-display"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>J</mi><mo stretchy="false">(</mo><mi mathvariant="bold-italic">θ</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>1</mn><mi>N</mi></mfrac><munderover><mo>∑</mo><mrow><mi>n</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><munderover><mo>∑</mo><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><msub><mi>T</mi><mi>n</mi></msub></munderover><mi>d</mi><mo stretchy="false">(</mo><msubsup><mi mathvariant="bold">y</mi><mi>t</mi><mrow><mo stretchy="false">(</mo><mi>n</mi><mo stretchy="false">)</mo></mrow></msubsup><mo separator="true">,</mo><msub><mi>f</mi><mi>o</mi></msub><mo stretchy="false">(</mo><msubsup><mi mathvariant="bold">h</mi><mi>t</mi><mrow><mo stretchy="false">(</mo><mi>n</mi><mo stretchy="false">)</mo></mrow></msubsup><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo separator="true">,</mo></mrow><annotation encoding="application/x-tex">
    J(\TT) = \frac{1}{N} \sum_{n=1}^N \sum_{t=1}^{T_n} 
    d(\vy_t^{(n)}, f_o(\vh_t^{(n)})),</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.09618em;">J</span><span class="mopen">(</span><span class="mord"><span class="mord"><span class="mord"><span class="mord boldsymbol" style="margin-right:0.03194em;">θ</span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:3.1065em;vertical-align:-1.2671em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3214em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283em;"><span style="top:-1.8829em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2671em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8394em;"><span style="top:-1.8829em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3111em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1645em;"><span style="top:-2.357em;margin-left:-0.1389em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2671em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">d</span><span class="mopen">(</span><span class="mord"><span class="mord mathbf" style="margin-right:0.01597em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0448em;"><span style="top:-2.4542em;margin-left:-0.016em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span><span style="top:-3.2198em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">n</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2458em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.1076em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">o</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathbf">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0448em;"><span style="top:-2.4542em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span><span style="top:-3.2198em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">n</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2458em;"><span></span></span></span></span></span></span><span class="mclose">))</span><span class="mpunct">,</span></span></span></span></span></div>

<p>where <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi mathvariant="bold">h</mi><mi>t</mi><mrow><mo stretchy="false">(</mo><mi>n</mi><mo stretchy="false">)</mo></mrow></msubsup><mo>=</mo><msub><mi>f</mi><mi>h</mi></msub><mo stretchy="false">(</mo><msubsup><mi mathvariant="bold">x</mi><mi>t</mi><mrow><mo stretchy="false">(</mo><mi>n</mi><mo stretchy="false">)</mo></mrow></msubsup><mo separator="true">,</mo><msubsup><mi mathvariant="bold">h</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow><mrow><mo stretchy="false">(</mo><mi>n</mi><mo stretchy="false">)</mo></mrow></msubsup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\vh_t^{(n)}=f_h(\vx_t^{(n)}, \vh_{t-1}^{(n)})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2906em;vertical-align:-0.2458em;"></span><span class="mord"><span class="mord mathbf">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0448em;"><span style="top:-2.4542em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span><span style="top:-3.2198em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">n</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2458em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.3694em;vertical-align:-0.3246em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.1076em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">h</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathbf">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0448em;"><span style="top:-2.4542em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span><span style="top:-3.2198em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">n</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2458em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathbf">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0448em;"><span style="top:-2.4337em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2198em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">n</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3246em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span> and
<span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi mathvariant="bold">h</mi><mn>0</mn><mrow><mo stretchy="false">(</mo><mi>n</mi><mo stretchy="false">)</mo></mrow></msubsup><mo>=</mo><mn mathvariant="bold">0</mn></mrow><annotation encoding="application/x-tex">\vh_0^{(n)}=\vzero</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.3111em;vertical-align:-0.2663em;"></span><span class="mord"><span class="mord mathbf">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0448em;"><span style="top:-2.4337em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span><span style="top:-3.2198em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">n</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2663em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord mathbf">0</span></span></span></span></span>. <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi><mo stretchy="false">(</mo><mi mathvariant="bold">a</mi><mo separator="true">,</mo><mi mathvariant="bold">b</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">d(\va, \vb)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">d</span><span class="mopen">(</span><span class="mord mathbf">a</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathbf">b</span><span class="mclose">)</span></span></span></span></span> is a predefined divergence
measure between <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">a</mi></mrow><annotation encoding="application/x-tex">\va</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4444em;"></span><span class="mord mathbf">a</span></span></span></span></span> and <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">b</mi></mrow><annotation encoding="application/x-tex">\vb</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathbf">b</span></span></span></span></span>, such as Euclidean distance or
cross-entropy.</p>

### Conventional Recurrent Neural Networks

<p>A conventional RNN is constructed by defining the transition
function and the output function as</p>

<div class="math-display"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi mathvariant="bold">h</mi><mi>t</mi></msub><mo>=</mo><msub><mi>f</mi><mi>h</mi></msub><mo stretchy="false">(</mo><msub><mi mathvariant="bold">x</mi><mi>t</mi></msub><mo separator="true">,</mo><msub><mi mathvariant="bold">h</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo stretchy="false">)</mo><mo>=</mo><msub><mi>ϕ</mi><mi>h</mi></msub><mrow><mo fence="true">(</mo><msup><mi mathvariant="bold">W</mi><mi mathvariant="normal">⊤</mi></msup><msub><mi mathvariant="bold">h</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo>+</mo><msup><mi mathvariant="bold">U</mi><mi mathvariant="normal">⊤</mi></msup><msub><mi mathvariant="bold">x</mi><mi>t</mi></msub><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">
    \vh_t  = f_h(\vx_t, \vh_{t-1}) = \phi_h\left(\mW^\top
    \vh_{t-1} + \mU^\top \vx_t \right)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathbf">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.1076em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">h</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathbf">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathbf">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2083em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.2491em;vertical-align:-0.35em;"></span><span class="mord"><span class="mord mathnormal">ϕ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">h</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size1">(</span></span><span class="mord"><span class="mord mathbf" style="margin-right:0.01597em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8991em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">⊤</span></span></span></span></span></span></span></span><span class="mord"><span class="mord mathbf">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2083em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord"><span class="mord mathbf">U</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8991em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">⊤</span></span></span></span></span></span></span></span><span class="mord"><span class="mord mathbf">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size1">)</span></span></span></span></span></span></span></div>
<div class="math-display"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi mathvariant="bold">y</mi><mi>t</mi></msub><mo>=</mo><msub><mi>f</mi><mi>o</mi></msub><mo stretchy="false">(</mo><msub><mi mathvariant="bold">h</mi><mi>t</mi></msub><mo separator="true">,</mo><msub><mi mathvariant="bold">x</mi><mi>t</mi></msub><mo stretchy="false">)</mo><mo>=</mo><msub><mi>ϕ</mi><mi>o</mi></msub><mrow><mo fence="true">(</mo><msup><mi mathvariant="bold">V</mi><mi mathvariant="normal">⊤</mi></msup><msub><mi mathvariant="bold">h</mi><mi>t</mi></msub><mo fence="true">)</mo></mrow><mo separator="true">,</mo></mrow><annotation encoding="application/x-tex">
    \vy_t  = f_o(\vh_t, \vx_t) = \phi_o\left(\mV^\top
    \vh_{t}\right),</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6389em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathbf" style="margin-right:0.01597em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:-0.016em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.1076em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">o</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathbf">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathbf">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.2491em;vertical-align:-0.35em;"></span><span class="mord"><span class="mord mathnormal">ϕ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">o</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size1">(</span></span><span class="mord"><span class="mord mathbf" style="margin-right:0.01597em;">V</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8991em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">⊤</span></span></span></span></span></span></span></span><span class="mord"><span class="mord mathbf">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size1">)</span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mpunct">,</span></span></span></span></span></div>

<p>where <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">W</mi></mrow><annotation encoding="application/x-tex">\mW</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6861em;"></span><span class="mord mathbf" style="margin-right:0.01597em;">W</span></span></span></span></span>, <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">U</mi></mrow><annotation encoding="application/x-tex">\mU</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6861em;"></span><span class="mord mathbf">U</span></span></span></span></span> and <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">V</mi></mrow><annotation encoding="application/x-tex">\mV</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6861em;"></span><span class="mord mathbf" style="margin-right:0.01597em;">V</span></span></span></span></span> are respectively the transition, input and output
matrices, and <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>ϕ</mi><mi>h</mi></msub></mrow><annotation encoding="application/x-tex">\phi_h</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal">ϕ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">h</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span> and <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>ϕ</mi><mi>o</mi></msub></mrow><annotation encoding="application/x-tex">\phi_o</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal">ϕ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">o</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span> are element-wise nonlinear functions. It is
usual to use a saturating nonlinear function such as a logistic sigmoid
function or a hyperbolic tangent function for <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>ϕ</mi><mi>h</mi></msub></mrow><annotation encoding="application/x-tex">\phi_h</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal">ϕ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">h</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span>. An illustration of this
RNN is in Fig.~<a href="#fig:rnn_models" class="cross-ref">Fig. 2</a> (a).</p>

<p>The parameters of the conventional RNN can be estimated by, for instance,
stochastic gradient descent (SGD) algorithm with the gradient of the cost
function in Eq.~<a href="#eq:cost_function" class="eq-ref">(2)</a> computed by backpropagation through
time~<sup class="ref-badge" data-ref="44" data-title="Learning representations by back-propagating errors.">44</sup>.</p>

<hr>

<h2>3. Deep Recurrent Neural Networks</h2>

<span id="sec:drnn" class="label-anchor"></span>

### Why Deep Recurrent Neural Networks?

<p>Deep learning is built around a hypothesis that a deep,
hierarchical model can be exponentially more efficient at
representing some functions than a shallow one~<sup class="ref-badge" data-ref="3" data-title="Learning deep architectures for AI.">3</sup>. A number of recent theoretical results
support this hypothesis~\citep[see,
e.g.,][]{Roux2010,Delalleau+Bengio-2011-small, Pascanu2014}. For instance, it
has been shown by [Delalleau+Bengio-2011-small] that a deep
sum-product network may require exponentially less units to
represent the same function compared to a shallow sum-product
network. Furthermore, there is a wealth of empirical evidences
supporting this hypothesis~\citep[see,
e.g.,][]{Goodfellow_maxout_2013,Hinton-et-al-arxiv2012,Hinton-et-al-2012}.
These findings make us suspect that the same argument should
apply to recurrent neural networks.</p>

### Depth of a Recurrent Neural Network
<span id="sec:depth_rnn" class="label-anchor"></span>

<p>The *depth* is defined in the case of feedforward neural networks as
having multiple nonlinear layers between input and output. Unfortunately this
definition does not apply trivially to a recurrent neural network (RNN) because
of its temporal structure. For instance, any RNN when unfolded in time as in
Fig.~<a href="#fig:model1_unfolded" class="cross-ref">Fig. 1</a> is deep, because a computational path between
the input at time <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi><mo>&lt;</mo><mi>t</mi></mrow><annotation encoding="application/x-tex">k &lt; t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7335em;vertical-align:-0.0391em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6151em;"></span><span class="mord mathnormal">t</span></span></span></span></span> to the output at time <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi></mrow><annotation encoding="application/x-tex">t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6151em;"></span><span class="mord mathnormal">t</span></span></span></span></span> crosses several nonlinear
layers.</p>

<p>A close analysis of the computation carried out by an RNN (see
Fig.~<a href="#fig:rnn_models" class="cross-ref">Fig. 2</a> (a)) at each time step individually, however, shows
that certain transitions are not deep, but are only results of a linear
projection followed by an element-wise nonlinearity.  It is clear that the
hidden-to-hidden (<span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">h</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo>→</mo><msub><mi mathvariant="bold">h</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">\vh_{t-1} \to \vh_{t}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9028em;vertical-align:-0.2083em;"></span><span class="mord"><span class="mord mathbf">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2083em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">→</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathbf">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span>), hidden-to-output ($\vh_{t} \to
\vy_{t}<span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">)</mo><mi>a</mi><mi>n</mi><mi>d</mi><mi>i</mi><mi>n</mi><mi>p</mi><mi>u</mi><mi>t</mi><mo>−</mo><mi>t</mi><mi>o</mi><mo>−</mo><mi>h</mi><mi>i</mi><mi>d</mi><mi>d</mi><mi>e</mi><mi>n</mi><mo stretchy="false">(</mo></mrow><annotation encoding="application/x-tex">) and input-to-hidden (</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mclose">)</span><span class="mord mathnormal">an</span><span class="mord mathnormal">d</span><span class="mord mathnormal">in</span><span class="mord mathnormal">p</span><span class="mord mathnormal">u</span><span class="mord mathnormal">t</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6984em;vertical-align:-0.0833em;"></span><span class="mord mathnormal">t</span><span class="mord mathnormal">o</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">hi</span><span class="mord mathnormal">dd</span><span class="mord mathnormal">e</span><span class="var" data-var="n" data-desc="Sequence length" style="--var-color: #c678dd"><span class="mord mathnormal">n</span></span><span class="mopen">(</span></span></span></span></span>\vx_t \to \vh_t$) functions are all
*shallow* in the sense that there exists no intermediate, nonlinear
hidden layer.</p>

<p>We can now consider different types of depth of an RNN by considering those
transitions separately.  We may make the hidden-to-hidden transition deeper by
having one or more intermediate nonlinear layers between two consecutive hidden
states (<span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">h</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">\vh_{t-1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9028em;vertical-align:-0.2083em;"></span><span class="mord"><span class="mord mathbf">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2083em;"><span></span></span></span></span></span></span></span></span></span></span> and <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">h</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">\vh_{t}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathbf">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span>). At the same time, the hidden-to-output
function can be made deeper, as described previously, by plugging, multiple
intermediate nonlinear layers between the hidden state <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">h</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">\vh_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathbf">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span> and the output
<span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">y</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">\vy_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6389em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathbf" style="margin-right:0.01597em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:-0.016em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span>.  Each of these choices has a different implication.</p>

#### Deep Input-to-Hidden Function

<p>A model can exploit more non-temporal structure from the input by making the
input-to-hidden function deep.  Previous work has shown that higher-level
representations of deep networks tend to better disentangle the underlying
factors of variation than the original
input~<sup class="ref-badge" data-ref="13" data-title="Measuring invariances in deep networks.">13</sup>[Glorot+al-ICML-2011-small] and flatten the
manifolds near which the data concentrate~<sup class="ref-badge" data-ref="5" data-title="Better mixing via deep representations.">5</sup>.  We
hypothesize that such higher-level representations should make it easier to
learn the temporal structure between successive time steps because the
relationship between abstract features can generally be expressed more easily.
This has been, for instance, illustrated by the recent
work~<sup class="ref-badge" data-ref="38" data-title="Efficient estimation of word representations in vector space.">38</sup> showing that word embeddings from neural
language models tend to be related to their temporal neighbors by simple
algebraic relationships, with the same type of relationship (adding a vector)
holding over very different regions of the space, allowing a form of analogical
reasoning.</p>

<p>This approach of making the input-to-hidden function deeper is in the line with
the standard practice of replacing input with extracted features in order to
improve the performance of a machine learning model~\citep[see,
e.g.,][]{Bengio2009FTML}.  Recently, <sup class="ref-badge" data-ref="8" data-title="A new method for learning deep recurrent neural networks.">8</sup> reported that a better
speech recognition performance could be achieved by employing this strategy,
although they did not jointly train the deep input-to-hidden function together
with other parameters of an RNN.</p>

#### Deep Hidden-to-Output Function

<p>A deep hidden-to-output function can be useful to disentangle the factors of
variations in the hidden state, making it easier to predict the output. This
allows the hidden state of the model to be more compact and may result in the
model being able to summarize the history of previous inputs more efficiently.
Let us denote an RNN with this deep hidden-to-output function a deep output RNN
(DO-RNN).</p>

<p>Instead of having feedforward, intermediate layers between the hidden state and
the output, [Boulanger+al-ICML2012-small] proposed to replace the output
layer with a conditional generative model such as restricted Boltzmann machines
or neural autoregressive distribution estimator~[Larochelle+Murray-2011].
In this paper we only consider feedforward intermediate layers.</p>

#### Deep Hidden-to-Hidden Transition
<span id="sec:deep_hid_to_hid" class="label-anchor"></span>

<p>The third knob we can play with is the depth of the hidden-to-hidden
transition.  The state transition between the consecutive hidden states
effectively adds a new input to the summary of the previous inputs represented
by the fixed-length hidden state. Previous work with RNNs has generally limited
the architecture to a shallow operation; affine transformation followed by an
element-wise nonlinearity. Instead, we argue that this procedure of
constructing a new summary, or a hidden state, from the combination of the
previous one and the new input should be highly nonlinear. This nonlinear
transition could allow, for instance, the hidden state of an RNN to rapidly
adapt to quickly changing modes of the input, while still preserving a useful
summary of the past. This may be impossible to be modeled by a function from
the family of generalized linear models. However, this highly nonlinear
transition can be modeled by an MLP with one or more hidden layers which has an
universal approximator property~\citep[see, e.g.,][]{Hornik89}.</p>

<p>An RNN with this deep transition will be called a deep transition RNN (DT-RNN)
throughout remainder of this paper. This model is shown in
Fig.~<a href="#fig:rnn_models" class="cross-ref">Fig. 2</a> (b).</p>

<p>This approach of having a deep transition, however, introduces a potential
problem. As the introduction of deep transition increases the number of
nonlinear steps the gradient has to traverse when propagated back in time, it
might become more difficult to train the model to capture long-term
dependencies~<sup class="ref-badge" data-ref="4" data-title="Learning long-term dependencies with gradient descent is difficult.">4</sup>. One possible way to address this difficulty
is to introduce shortcut connections~\citep[see, e.g.,][]{Raiko2012} in the
deep transition, where the added shortcut connections provide shorter paths,
skipping the intermediate layers, through which the gradient is propagated back
in time.  We refer to an RNN having deep transition with shortcut connections
by DT(S)-RNN (See Fig.~<a href="#fig:rnn_models" class="cross-ref">Fig. 2</a> (b*)).</p>

<p>Furthermore, we will call an RNN having both a deep hidden-to-output function
and a deep transition a deep output, deep transition RNN (DOT-RNN).  See
Fig.~<a href="#fig:rnn_models" class="cross-ref">Fig. 2</a> (c) for the illustration of DOT-RNN. If we consider
shortcut connections as well in the hidden to hidden transition, we call the
resulting model DOT(S)-RNN.</p>

<p>An approach similar to the deep hidden-to-hidden transition has been proposed
recently by <sup class="ref-badge" data-ref="42" data-title="Recurrent convolutional neural networks for scene labeling.">42</sup> in the context of parsing a static scene.  They
introduced a recurrent convolutional neural network (RCNN) which can be
understood as a recurrent network whose the transition between consecutive
hidden states (and input to hidden state) is modeled by a convolutional neural
network.</p>

<p>The RCNN was shown to speed up scene parsing and obtained the state-of-the-art
result in Stanford Background and SIFT Flow datasets. <sup class="ref-badge" data-ref="26" data-title="Gp-bayesfilters: Bayesian filtering using gaussian process prediction">26</sup> proposed deep
transitions for Gaussian Process models. Earlier, <sup class="ref-badge" data-ref="48" data-title="An unsupervised ensemble learning method for nonlinear dynamic">48</sup> used a
deep neural network to model the state transition in a nonlinear, dynamical
state-space model.</p>

#### Stack of Hidden States

<p>An RNN may be extended deeper in yet another way by stacking multiple recurrent
hidden layers on top of each other~<sup class="ref-badge" data-ref="45" data-title="Learning complex, extended sequences using the principle of history">45</sup>[ElHihi+Bengio-nips8]<sup class="ref-badge" data-ref="25" data-title="Discovering multiscale dynamical features with hierarchical echo">25</sup><sup class="ref-badge" data-ref="16" data-title="Generating sequences with recurrent neural networks.">16</sup>.  We call this model a stacked
RNN (sRNN) to distinguish it from the other proposed variants.  The goal of a
such model is to encourage each recurrent level to operate at a different
timescale.</p>

<p>It should be noticed that the DT-RNN and the sRNN extend the conventional,
shallow RNN in different aspects. If we look at each recurrent level of the
sRNN separately, it is easy to see that the transition between the consecutive
hidden states is still shallow. As we have argued above,  this limits the
family of functions it can represent. For example, if the structure of the data
is sufficiently complex, incorporating a new input frame into the summary of
what had been seen up to now might be an arbitrarily complex function. In such
a case we would like to model this function by something that has universal
approximator properties, as an MLP. The model can not rely on the higher layers
to do so, because the higher layers do not feed back into the lower layer.  On
the other hand, the sRNN can deal with multiple time scales in the input
sequence, which is not an obvious feature of the DT-RNN. The DT-RNN and the
sRNN are, however, orthogonal in the sense that it is possible to have both
features of the DT-RNN and the sRNN by stacking multiple levels of DT-RNNs to
build a stacked DT-RNN which we do not explore more in this paper.</p>

### Formal descriptions of deep RNNs

<p>Here we give a more formal description on how the deep transition
recurrent neural network (DT-RNN) and the deep output RNN
(DO-RNN) as well as the stacked RNN are implemented.</p>

#### Deep Transition RNN
<span id="sec:dt_rnn" class="label-anchor"></span>

<p>We noticed from the state transition equation of the dynamical
system simulated by RNNs in Eq.~<a href="#eq:dynamical_system_trans" class="eq-ref">(1)</a>
that there is no restriction on the form of <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>f</mi><mi>h</mi></msub></mrow><annotation encoding="application/x-tex">f_h</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.1076em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">h</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span>. Hence, we
propose here to use a multilayer perceptron to approximate <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>f</mi><mi>h</mi></msub></mrow><annotation encoding="application/x-tex">f_h</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.1076em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">h</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span>
instead.</p>

<p>In this case, we can implement <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>f</mi><mi>h</mi></msub></mrow><annotation encoding="application/x-tex">f_h</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.1076em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">h</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span> by <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi></mrow><annotation encoding="application/x-tex">L</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">L</span></span></span></span></span> intermediate layers
such that</p>

<div class="math-display"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi mathvariant="bold">h</mi><mi>t</mi></msub><mo>=</mo><msub><mi>f</mi><mi>h</mi></msub><mo stretchy="false">(</mo><msub><mi mathvariant="bold">x</mi><mi>t</mi></msub><mo separator="true">,</mo><msub><mi mathvariant="bold">h</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo stretchy="false">)</mo><mo>=</mo><msub><mi>ϕ</mi><mi>h</mi></msub><mrow><mo fence="true">(</mo><msubsup><mi mathvariant="bold">W</mi><mi>L</mi><mi mathvariant="normal">⊤</mi></msubsup><msub><mi>ϕ</mi><mrow><mi>L</mi><mo>−</mo><mn>1</mn></mrow></msub><mrow><mo fence="true">(</mo><msubsup><mi mathvariant="bold">W</mi><mrow><mi>L</mi><mo>−</mo><mn>1</mn></mrow><mi mathvariant="normal">⊤</mi></msubsup><msub><mi>ϕ</mi><mrow><mi>L</mi><mo>−</mo><mn>2</mn></mrow></msub><mrow><mo fence="true">(</mo><mo>⋯</mo><msub><mi>ϕ</mi><mn>1</mn></msub><mrow><mo fence="true">(</mo><msubsup><mi mathvariant="bold">W</mi><mn>1</mn><mi mathvariant="normal">⊤</mi></msubsup><msub><mi mathvariant="bold">h</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo>+</mo><msup><mi mathvariant="bold">U</mi><mi mathvariant="normal">⊤</mi></msup><msub><mi mathvariant="bold">x</mi><mi>t</mi></msub><mo fence="true">)</mo></mrow><mo fence="true">)</mo></mrow><mo fence="true">)</mo></mrow><mo fence="true">)</mo></mrow><mo separator="true">,</mo></mrow><annotation encoding="application/x-tex">\vh_t  = f_h(\vx_t, \vh_{t-1}) = \phi_h \left(
    \mW_L^\top \phi_{L-1} \left(
    \mW_{L-1}^\top \phi_{L-2} \left(
    \cdots \phi_{1} \left(
    \mW_{1}^\top \vh_{t-1} + \mU^\top \vx_t
    \right)
    \right)
    \right)
    \right),</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathbf">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.1076em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">h</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathbf">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathbf">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2083em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.2491em;vertical-align:-0.35em;"></span><span class="mord"><span class="mord mathnormal">ϕ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">h</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size1">(</span></span><span class="mord"><span class="mord mathbf" style="margin-right:0.01597em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8991em;"><span style="top:-2.453em;margin-left:-0.016em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">L</span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">⊤</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">ϕ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">L</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2083em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size1">(</span></span><span class="mord"><span class="mord mathbf" style="margin-right:0.01597em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8991em;"><span style="top:-2.453em;margin-left:-0.016em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">L</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">⊤</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3053em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">ϕ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">L</span><span class="mbin mtight">−</span><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2083em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size1">(</span></span><span class="minner">⋯</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">ϕ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size1">(</span></span><span class="mord"><span class="mord mathbf" style="margin-right:0.01597em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8991em;"><span style="top:-2.453em;margin-left:-0.016em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">⊤</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathbf">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2083em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord"><span class="mord mathbf">U</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8991em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">⊤</span></span></span></span></span></span></span></span><span class="mord"><span class="mord mathbf">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size1">)</span></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size1">)</span></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size1">)</span></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size1">)</span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mpunct">,</span></span></span></span></span></div>

<p>where <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>ϕ</mi><mi>l</mi></msub></mrow><annotation encoding="application/x-tex">\phi_{l}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal">ϕ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span> and <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">W</mi><mi>l</mi></msub></mrow><annotation encoding="application/x-tex">\mW_{l}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8361em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathbf" style="margin-right:0.01597em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.016em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span> are the element-wise nonlinear
function and the weight matrix for the <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>l</mi></mrow><annotation encoding="application/x-tex">l</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span></span></span></span></span>-th layer.  This RNN
with a multilayered transition function is a deep transition RNN
(DT-RNN).</p>

<p>An illustration of building an RNN with the deep state transition
function is shown in Fig.~<a href="#fig:rnn_models" class="cross-ref">Fig. 2</a> (b). In the
illustration the state transition function is implemented with a
neural network with a single intermediate layer.</p>

<p>This formulation allows the RNN to learn a non-trivial, highly
nonlinear transition between the consecutive hidden states.</p>

#### Deep Output RNN
<span id="sec:dot_rnn" class="label-anchor"></span>

<p>Similarly, we can use a multilayer perceptron with <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi></mrow><annotation encoding="application/x-tex">L</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">L</span></span></span></span></span>
intermediate layers to model the output function <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>f</mi><mi>o</mi></msub></mrow><annotation encoding="application/x-tex">f_o</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.1076em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">o</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span> in
Eq.~<a href="#eq:dynamical_system_out" class="eq-ref">(?)</a> such that</p>

<div class="math-display"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi mathvariant="bold">y</mi><mi>t</mi></msub><mo>=</mo><msub><mi>f</mi><mi>o</mi></msub><mo stretchy="false">(</mo><msub><mi mathvariant="bold">h</mi><mi>t</mi></msub><mo stretchy="false">)</mo><mo>=</mo><msub><mi>ϕ</mi><mi>o</mi></msub><mrow><mo fence="true">(</mo><msubsup><mi mathvariant="bold">V</mi><mi>L</mi><mi mathvariant="normal">⊤</mi></msubsup><msub><mi>ϕ</mi><mrow><mi>L</mi><mo>−</mo><mn>1</mn></mrow></msub><mrow><mo fence="true">(</mo><msubsup><mi mathvariant="bold">V</mi><mrow><mi>L</mi><mo>−</mo><mn>1</mn></mrow><mi mathvariant="normal">⊤</mi></msubsup><msub><mi>ϕ</mi><mrow><mi>L</mi><mo>−</mo><mn>2</mn></mrow></msub><mrow><mo fence="true">(</mo><mo>⋯</mo><msub><mi>ϕ</mi><mn>1</mn></msub><mrow><mo fence="true">(</mo><msubsup><mi mathvariant="bold">V</mi><mn>1</mn><mi mathvariant="normal">⊤</mi></msubsup><msub><mi mathvariant="bold">h</mi><mi>t</mi></msub><mo fence="true">)</mo></mrow><mo fence="true">)</mo></mrow><mo fence="true">)</mo></mrow><mo fence="true">)</mo></mrow><mo separator="true">,</mo></mrow><annotation encoding="application/x-tex">\vy_t  = f_o(\vh_t) = \phi_o \left(
    \mV_L^\top \phi_{L-1} \left(
    \mV_{L-1}^\top \phi_{L-2} \left(
    \cdots \phi_{1} \left(
    \mV_{1}^\top \vh_{t}
    \right)
    \right)
    \right)
    \right),</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6389em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathbf" style="margin-right:0.01597em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:-0.016em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.1076em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">o</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathbf">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.2491em;vertical-align:-0.35em;"></span><span class="mord"><span class="mord mathnormal">ϕ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">o</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size1">(</span></span><span class="mord"><span class="mord mathbf" style="margin-right:0.01597em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8991em;"><span style="top:-2.453em;margin-left:-0.016em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">L</span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">⊤</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">ϕ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">L</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2083em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size1">(</span></span><span class="mord"><span class="mord mathbf" style="margin-right:0.01597em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8991em;"><span style="top:-2.453em;margin-left:-0.016em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">L</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">⊤</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3053em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">ϕ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">L</span><span class="mbin mtight">−</span><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2083em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size1">(</span></span><span class="minner">⋯</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">ϕ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size1">(</span></span><span class="mord"><span class="mord mathbf" style="margin-right:0.01597em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8991em;"><span style="top:-2.453em;margin-left:-0.016em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">⊤</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathbf">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size1">)</span></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size1">)</span></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size1">)</span></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size1">)</span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mpunct">,</span></span></span></span></span></div>

<p>where <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>ϕ</mi><mi>l</mi></msub></mrow><annotation encoding="application/x-tex">\phi_{l}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal">ϕ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span> and <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">V</mi><mi>l</mi></msub></mrow><annotation encoding="application/x-tex">\mV_{l}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8361em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathbf" style="margin-right:0.01597em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.016em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span> are the element-wise nonlinear
function and the weight matrix for the <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>l</mi></mrow><annotation encoding="application/x-tex">l</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span></span></span></span></span>-th layer.  An RNN
implementing this kind of multilayered output function is a deep
output recurrent neural network (DO-RNN).</p>

<p>Fig.~<a href="#fig:rnn_models" class="cross-ref">Fig. 2</a> (c) draws a deep output, deep
transition RNN (DOT-RNN) implemented using both the deep
transition and the deep output with a single intermediate layer
each.</p>

#### Stacked RNN

<p>The stacked RNN~<sup class="ref-badge" data-ref="45" data-title="Learning complex, extended sequences using the principle of history">45</sup>[ElHihi+Bengio-nips8] has multiple levels of
transition functions defined by</p>

<div class="math-display"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msubsup><mi mathvariant="bold">h</mi><mi>t</mi><mrow><mo stretchy="false">(</mo><mi>l</mi><mo stretchy="false">)</mo></mrow></msubsup><mo>=</mo><msubsup><mi>f</mi><mi>h</mi><mrow><mo stretchy="false">(</mo><mi>l</mi><mo stretchy="false">)</mo></mrow></msubsup><mo stretchy="false">(</mo><msubsup><mi mathvariant="bold">h</mi><mi>t</mi><mrow><mo stretchy="false">(</mo><mi>l</mi><mo>−</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></msubsup><mo separator="true">,</mo><msubsup><mi mathvariant="bold">h</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow><mrow><mo stretchy="false">(</mo><mi>l</mi><mo stretchy="false">)</mo></mrow></msubsup><mo stretchy="false">)</mo><mo>=</mo><msub><mi>ϕ</mi><mi>h</mi></msub><mrow><mo fence="true">(</mo><msubsup><mi mathvariant="bold">W</mi><mi>l</mi><mi mathvariant="normal">⊤</mi></msubsup><msubsup><mi mathvariant="bold">h</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow><mrow><mo stretchy="false">(</mo><mi>l</mi><mo stretchy="false">)</mo></mrow></msubsup><mo>+</mo><msubsup><mi mathvariant="bold">U</mi><mi>l</mi><mi mathvariant="normal">⊤</mi></msubsup><msubsup><mi mathvariant="bold">h</mi><mi>t</mi><mrow><mo stretchy="false">(</mo><mi>l</mi><mo>−</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></msubsup><mo fence="true">)</mo></mrow><mo separator="true">,</mo></mrow><annotation encoding="application/x-tex">\vh_t^{(l)}  = f_h^{(l)}(\vh_{t}^{(l-1)}, \vh_{t-1}^{(l)}) = 
    \phi_h\left(\mW_{l}^\top \vh_{t-1}^{(l)} + 
    \mU_{l}^\top \vh_{t}^{(l-1)} \right),</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2906em;vertical-align:-0.2458em;"></span><span class="mord"><span class="mord mathbf">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0448em;"><span style="top:-2.4542em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span><span style="top:-3.2198em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2458em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.3694em;vertical-align:-0.3246em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0448em;"><span style="top:-2.3987em;margin-left:-0.1076em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">h</span></span></span><span style="top:-3.2198em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3013em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathbf">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0448em;"><span style="top:-2.4542em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span style="top:-3.2198em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mbin mtight">−</span><span class="mord mtight">1</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2458em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathbf">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0448em;"><span style="top:-2.4337em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2198em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3246em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.8em;vertical-align:-0.65em;"></span><span class="mord"><span class="mord mathnormal">ϕ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">h</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size2">(</span></span><span class="mord"><span class="mord mathbf" style="margin-right:0.01597em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8991em;"><span style="top:-2.453em;margin-left:-0.016em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">⊤</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathbf">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0448em;"><span style="top:-2.4337em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2198em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3246em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord"><span class="mord mathbf">U</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8991em;"><span style="top:-2.453em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">⊤</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathbf">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0448em;"><span style="top:-2.4542em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span style="top:-3.2198em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mbin mtight">−</span><span class="mord mtight">1</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2458em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size2">)</span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mpunct">,</span></span></span></span></span></div>

<p>where <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi mathvariant="bold">h</mi><mi>t</mi><mrow><mo stretchy="false">(</mo><mi>l</mi><mo stretchy="false">)</mo></mrow></msubsup></mrow><annotation encoding="application/x-tex">\vh_t^{(l)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2906em;vertical-align:-0.2458em;"></span><span class="mord"><span class="mord mathbf">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0448em;"><span style="top:-2.4542em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span><span style="top:-3.2198em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2458em;"><span></span></span></span></span></span></span></span></span></span></span> is the hidden state of the <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>l</mi></mrow><annotation encoding="application/x-tex">l</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span></span></span></span></span>-th level at
time <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi></mrow><annotation encoding="application/x-tex">t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6151em;"></span><span class="mord mathnormal">t</span></span></span></span></span>.  When <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>l</mi><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">l=1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1</span></span></span></span></span>, the state is computed using <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">x</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">\vx_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5944em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathbf">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span>
instead of <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi mathvariant="bold">h</mi><mi>t</mi><mrow><mo stretchy="false">(</mo><mi>l</mi><mo>−</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></msubsup></mrow><annotation encoding="application/x-tex">\vh_{t}^{(l-1)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2906em;vertical-align:-0.2458em;"></span><span class="mord"><span class="mord mathbf">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0448em;"><span style="top:-2.4542em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span style="top:-3.2198em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mbin mtight">−</span><span class="mord mtight">1</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2458em;"><span></span></span></span></span></span></span></span></span></span></span>. The hidden states of all the levels
are recursively computed from the bottom level <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>l</mi><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">l=1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1</span></span></span></span></span>.</p>

<p>Once the top-level hidden state is computed, the output can be
obtained using the usual formulation in
Eq.~<a href="#eq:rnn_shallow_out" class="eq-ref">(?)</a>. Alternatively, one may use all
the hidden states to compute the output~<sup class="ref-badge" data-ref="20" data-title="Training and analysing deep recurrent neural networks.">20</sup>. Each
hidden state at each level may also be made to depend on the
input as well~<sup class="ref-badge" data-ref="16" data-title="Generating sequences with recurrent neural networks.">16</sup>. Both of them can be considered
approaches using shortcut connections discussed earlier.</p>

<p>The illustration of this stacked RNN is in
Fig.~<a href="#fig:rnn_models" class="cross-ref">Fig. 2</a> (d).</p>

<hr>

<h2>4. Another Perspective: Neural Operators</h2>

<p>In this section, we briefly introduce a novel approach with which
the already discussed deep transition (DT) and/or deep output
(DO) recurrent neural networks (RNN) may be built. We call this
approach which is based on building an RNN with a set of
predefined neural operators, an operator-based framework.</p>

<p>In the operator-based framework, one first defines a set of
operators of which each is implemented by a multilayer perceptron
(MLP). For instance, a *plus* operator <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>⊕</mo></mrow><annotation encoding="application/x-tex">\oplus</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6667em;vertical-align:-0.0833em;"></span><span class="mord">⊕</span></span></span></span></span> may be
defined as a function receiving two vectors <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">x</mi></mrow><annotation encoding="application/x-tex">\vx</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4444em;"></span><span class="mord mathbf">x</span></span></span></span></span> and <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">h</mi></mrow><annotation encoding="application/x-tex">\vh</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathbf">h</span></span></span></span></span> and
returning the summary <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi mathvariant="bold">h</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup></mrow><annotation encoding="application/x-tex">\vh&#x27;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7519em;"></span><span class="mord"><span class="mord mathbf">h</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7519em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span></span> of them:</p>

<div class="math-display"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msup><mi mathvariant="bold">h</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo>=</mo><mi mathvariant="bold">x</mi><mo>⊕</mo><mi mathvariant="bold">h</mi><mo separator="true">,</mo></mrow><annotation encoding="application/x-tex">\vh&#x27; = \vx \oplus \vh,</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8019em;"></span><span class="mord"><span class="mord mathbf">h</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8019em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6667em;vertical-align:-0.0833em;"></span><span class="mord mathbf">x</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⊕</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathbf">h</span><span class="mpunct">,</span></span></span></span></span></div>

<p>where we may constrain that the dimensionality of <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">h</mi></mrow><annotation encoding="application/x-tex">\vh</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathbf">h</span></span></span></span></span> and
<span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi mathvariant="bold">h</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup></mrow><annotation encoding="application/x-tex">\vh&#x27;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7519em;"></span><span class="mord"><span class="mord mathbf">h</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7519em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span></span> are identical.  Additionally, we can define another
operator <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>⊳</mo></mrow><annotation encoding="application/x-tex">\rhd</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.585em;vertical-align:-0.0352em;"></span><span class="mord amsrm">⊳</span></span></span></span></span> which *predicts* the most likely output
symbol <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi mathvariant="bold">x</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup></mrow><annotation encoding="application/x-tex">\vx&#x27;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7519em;"></span><span class="mord"><span class="mord mathbf">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7519em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span></span> given a summary <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">h</mi></mrow><annotation encoding="application/x-tex">\vh</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathbf">h</span></span></span></span></span>, such that</p>

<div class="math-display"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msup><mi mathvariant="bold">x</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo>=</mo><mo>⊳</mo><mi mathvariant="bold">h</mi></mrow><annotation encoding="application/x-tex">\vx&#x27; = \rhd \vh</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8019em;"></span><span class="mord"><span class="mord mathbf">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8019em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.7296em;vertical-align:-0.0352em;"></span><span class="mord amsrm">⊳</span><span class="mord mathbf">h</span></span></span></span></span></div>

<p>It is possible to define many other operators, but in this paper,
we stick to these two operators which are sufficient to express
all the proposed types of RNNs.</p>

<p>\begin{wrapfigure}{I}{0.4\textwidth}
    \centering
    \includegraphics[width=0.25\columnwidth]{model_operator.pdf}
\caption{A view of
an RNN under the operator-based framework: <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>⊕</mo></mrow><annotation encoding="application/x-tex">\oplus</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6667em;vertical-align:-0.0833em;"></span><span class="mord">⊕</span></span></span></span></span> and <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>⊳</mo></mrow><annotation encoding="application/x-tex">\rhd</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.585em;vertical-align:-0.0352em;"></span><span class="mord amsrm">⊳</span></span></span></span></span>
are the *plus* and *predict* operators,
respectively. }
<span id="fig:model_operator" class="label-anchor"></span>
\vskip -3mm
\end{wrapfigure}</p>

<p>It is clear to see that the plus operator <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>⊕</mo></mrow><annotation encoding="application/x-tex">\oplus</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6667em;vertical-align:-0.0833em;"></span><span class="mord">⊕</span></span></span></span></span> and the
predict operator <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>⊳</mo></mrow><annotation encoding="application/x-tex">\rhd</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.585em;vertical-align:-0.0352em;"></span><span class="mord amsrm">⊳</span></span></span></span></span> correspond to the transition function and
the output function in
Eqs.~<a href="#eq:dynamical_system_trans" class="eq-ref">(1)</a>--<a href="#eq:dynamical_system_out" class="eq-ref">(?)</a>.
Thus, at each step, an RNN can be thought as performing the plus
operator to update the hidden state given an input ($\vh_t =
\vx_t \oplus \vh_{t-1}$) and then the predict operator to compute
the output ($\vy_t = \rhd \vh_t = \rhd (\vx_t \oplus
\vh_{t-1})$). See Fig.~<a href="#fig:model_operator" class="cross-ref"> ?</a> for the
illustration of how an RNN can be understood from the
operator-based framework.</p>

<p>Each operator can be parameterized as an MLP with one or more
hidden layers, hence a neural operator, since we cannot simply
expect the operation will be linear with respect to the input
vector(s).  By using an MLP to implement the operators, the
proposed deep transition, deep output RNN (DOT-RNN) naturally
arises.</p>

<p>This framework provides us an insight on how the constructed RNN
be regularized.  For instance, one may regularize the model such
that the plus operator <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>⊕</mo></mrow><annotation encoding="application/x-tex">\oplus</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6667em;vertical-align:-0.0833em;"></span><span class="mord">⊕</span></span></span></span></span> is commutative. However, in this
paper, we do not explore further on this approach.</p>

<p>Note that this is different from <sup class="ref-badge" data-ref="37" data-title="Distributed representations of words and phrases and their">37</sup> where the
learned embeddings of words happened to be suitable for algebraic
operators. The operator-based framework proposed here is rather
geared toward *learning* these operators directly.</p>

<hr>

<h2>5. Experiments</h2>

<span id="sec:experiments" class="label-anchor"></span>

<p>We train four types of RNNs described in this paper on a number
of benchmark datasets to evaluate their performance. For each
benchmark dataset, we try the task of predicting the next symbol.</p>

<p>The task of predicting the next symbol is equivalent to the task
of modeling the distribution over a sequence.  For each sequence
<span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo fence="true">(</mo><msub><mi mathvariant="bold">x</mi><mn>1</mn></msub><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><msub><mi mathvariant="bold">x</mi><mi>T</mi></msub><mo fence="true">)</mo></mrow><annotation encoding="application/x-tex">\left( \vx_1, \dots, \vx_T \right)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord"><span class="mord mathbf">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathbf">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">)</span></span></span></span></span></span>, we decompose it into 
\[
    p(\vx_1, \dots, \vx_T) = p(\vx_1) \prod_{t=2}^T p(\vx_t \mid \vx_1,
    \dots, \vx_{t-1}),
\]
and each term on the right-hand side will be replaced with a
single timestep of an RNN. In this setting, the RNN predicts the
probability of the next symbol <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">x</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">\vx_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5944em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathbf">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span> in the sequence given the
all previous symbols <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">x</mi><mn>1</mn></msub><mo separator="true">,</mo><mo>…</mo><msub><mi mathvariant="bold">x</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">\vx_1,\dots\vx_{t-1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6528em;vertical-align:-0.2083em;"></span><span class="mord"><span class="mord mathbf">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathbf">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2083em;"><span></span></span></span></span></span></span></span></span></span></span>. Then, we train the
RNN by maximizing the log-likelihood.</p>

<p>We try this task of modeling the joint distribution on three
different tasks; polyphonic music prediction, character-level and
word-level language modeling.</p>

<p>We test the RNNs on the task of polyphonic music prediction using
three datasets which are Nottingham, JSB Chorales and MuseData~[Boulanger+al-ICML2012-small]. On the task of
character-level  and word-level language modeling, we use Penn
Treebank Corpus~<sup class="ref-badge" data-ref="29" data-title="Building a large annotated corpus of english: The Penn Treebank.">29</sup>.</p>

### Model Descriptions

<p>We compare the conventional recurrent neural network (RNN), deep
transition RNN with shortcut connections in the transition MLP
(DT(S)-RNN), deep output/transition RNN with shortcut connections
in the hidden to hidden transition MLP (DOT(S)-RNN) and stacked
RNN (sRNN).  See Fig.~<a href="#fig:rnn_models" class="cross-ref">Fig. 2</a> (a)--(d) for the
illustrations of these models.</p>

<table class="article-table">
  <caption>The sizes of the trained models. We provide the number 
        of hidden units as well as the total number of parameters.
        For DT(S)-RNN, the two numbers provided for the number of units 
        mean the size of the
        hidden state and that of the intermediate layer,
        respectively. For DOT(S)-RNN, the three numbers are the size
        of the hidden state, that of the intermediate layer
        between the consecutive hidden states and that of the
        intermediate layer between the hidden state and the
        output layer. For sRNN, the number corresponds to the size of
the hidden state at each level</caption>
  <thead><tr>
    <th>\multicolumn{3}{c||}{}</th>
    <th>RNN</th>
    <th>DT(S)-RNN</th>
    <th>DOT(S)-RNN</th>
    <th>sRNN</th>
  </tr></thead>
  <tbody>
  <tr>
    <td>\multicolumn{3}{c||}{}</td>
    <td></td>
    <td></td>
    <td></td>
    <td>2 layers</td>
  </tr>
  <tr>
    <td>\multirow{4}{*}{Music}</td>
    <td>Notthingam</td>
    <td>\specialcell{\# units</td>
  </tr>
  <tr>
    <td>\# parameters}</td>
    <td>\specialcell{600</td>
  </tr>
  <tr>
    <td>465K}</td>
    <td>\specialcell{400,400</td>
  </tr>
  <tr>
    <td>585K}</td>
    <td>\specialcell{400,400,400</td>
  </tr>
  <tr>
    <td>745K}</td>
    <td>\specialcell{ 400</td>
  </tr>
  <tr>
    <td>550K}</td>
  </tr>
  <tr>
    <td></td>
    <td>JSB Chorales</td>
    <td>\specialcell{\# units</td>
  </tr>
  <tr>
    <td>\# parameters}</td>
    <td>\specialcell{200</td>
  </tr>
  <tr>
    <td>75K}</td>
    <td>\specialcell{400,400</td>
  </tr>
  <tr>
    <td>585K }</td>
    <td>\specialcell{400,400,400</td>
  </tr>
  <tr>
    <td>745K}</td>
    <td>\specialcell{ 400</td>
  </tr>
  <tr>
    <td>550K}</td>
  </tr>
  <tr>
    <td></td>
    <td>MuseData</td>
    <td>\specialcell{\# units</td>
  </tr>
  <tr>
    <td>\# parameters}</td>
    <td>\specialcell{600</td>
  </tr>
  <tr>
    <td>465K}</td>
    <td>\specialcell{400,400</td>
  </tr>
  <tr>
    <td>585K}</td>
    <td>\specialcell{400,400,400</td>
  </tr>
  <tr>
    <td>745K}</td>
    <td>\specialcell{600</td>
  </tr>
  <tr>
    <td>1185K}</td>
  </tr>
  <tr>
    <td>\multirow{4}{*}{Language}</td>
    <td>Char-level</td>
    <td>\specialcell{\# units</td>
  </tr>
  <tr>
    <td>\# parameters}</td>
    <td>\specialcell{600</td>
  </tr>
  <tr>
    <td>420K}</td>
    <td>\specialcell{400,400</td>
  </tr>
  <tr>
    <td>540K}</td>
    <td>\specialcell{400,400,600</td>
  </tr>
  <tr>
    <td>790K}</td>
    <td>\specialcell{400</td>
  </tr>
  <tr>
    <td>520K}</td>
  </tr>
  <tr>
    <td></td>
    <td>Word-level</td>
    <td>\specialcell{\# units</td>
  </tr>
  <tr>
    <td>\# parameters}</td>
    <td>\specialcell{200</td>
  </tr>
  <tr>
    <td>4.04M}</td>
    <td>\specialcell{200,200</td>
  </tr>
  <tr>
    <td>6.12M}</td>
    <td>\specialcell{200,200,200</td>
  </tr>
  <tr>
    <td>6.16M}</td>
    <td>\specialcell{400</td>
  </tr>
  <tr>
    <td>8.48M}</td>
  </tr>
  </tbody>
</table>

<p>The size of each model is chosen from a limited set $\left\{ 100,
200, 400, 600, 800 \right\}$ to minimize the validation error for
each polyphonic music task (See Table.~<a href="#tab:model_size" class="cross-ref">Table 1</a> for
the final models). In the case of language modeling tasks, we
chose the size of the models from <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo fence="true">{</mo><mn>200</mn><mo separator="true">,</mo><mn>400</mn><mo fence="true">}</mo></mrow><annotation encoding="application/x-tex">\left\{ 200, 400 \right\}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">{</span><span class="mord">200</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">400</span><span class="mclose delimcenter" style="top:0em;">}</span></span></span></span></span></span> and
<span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo fence="true">{</mo><mn>400</mn><mo separator="true">,</mo><mn>600</mn><mo fence="true">}</mo></mrow><annotation encoding="application/x-tex">\left\{ 400, 600 \right\}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">{</span><span class="mord">400</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">600</span><span class="mclose delimcenter" style="top:0em;">}</span></span></span></span></span></span> for word-level and character-level
tasks, respectively.  In all cases, we use a logistic sigmoid
function as an element-wise nonlinearity of each hidden unit.
Only for the character-level language modeling we used rectified
linear units~[Glorot+al-AI-2011-small] for the intermediate
layers of the output function, which gave lower validation error.</p>

### Training

<p>We use stochastic gradient descent (SGD) and employ the strategy
of clipping the gradient proposed by
[Pascanu+al-ICML2013-small]. Training stops when the
validation cost stops decreasing.</p>

<p>**Polyphonic Music Prediction**: 
For Nottingham and MuseData datasets we compute each gradient
step on subsequences of at most 200 steps, while we use
subsequences of 50 steps for JSB Chorales. We do not reset the
hidden state for each subsequence, unless the subsequence belongs
to a different song than the previous subsequence.</p>

<p>The cutoff threshold for the
gradients is set to 1. The hyperparameter for the
learning rate schedule = \frac{1}{1 + \frac{\max(0, \tau -
        \tau_0)}{\beta}},
        $
    where <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>τ</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">\tau_0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.1132em;">τ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.1132em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span> and <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>β</mi></mrow><annotation encoding="application/x-tex">\beta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.05278em;">β</span></span></span></span></span> indicate respectively when the learning rate
    starts decreasing and how quickly the learning rate decreases. In the
    experiment, we set <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>τ</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">\tau_0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.1132em;">τ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.1132em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span> to coincide with the time when the validation
    error starts increasing for the first time. 
} 
is tuned manually for each dataset.  We set the hyperparameter
<span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>β</mi></mrow><annotation encoding="application/x-tex">\beta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.05278em;">β</span></span></span></span></span> to <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2330</mn></mrow><annotation encoding="application/x-tex">2330</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">2330</span></span></span></span></span> for Nottingham, <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1475</mn></mrow><annotation encoding="application/x-tex">1475</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1475</span></span></span></span></span> for MuseData and <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>100</mn></mrow><annotation encoding="application/x-tex">100</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">100</span></span></span></span></span>
for JSB Chroales.
They
correspond to two epochs, a single epoch and a third of an epoch, respectively.</p>

<p>The weights of the connections between any pair of hidden layers
are sparse, having only 20 non-zero incoming connections per unit~\citep[see, e.g.,][]{sutskeverimportance}. Each weight matrix is
rescaled to have a unit largest singular value~[Pascanu+al-ICML2013-small]. The weights of the connections
between the input layer and the hidden state as well as between
the hidden state and the output layer are initialized randomly
from the white Gaussian distribution with its standard deviation
fixed to <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0.1</mn></mrow><annotation encoding="application/x-tex">0.1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">0.1</span></span></span></span></span> and <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0.01</mn></mrow><annotation encoding="application/x-tex">0.01</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">0.01</span></span></span></span></span>, respectively. In the case of deep
output functions (DOT(S)-RNN), the weights of the connections
between the hidden state and the intermediate layer are sampled
initially from the white Gaussian distribution of standard
deviation <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0.01</mn></mrow><annotation encoding="application/x-tex">0.01</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">0.01</span></span></span></span></span>. In all cases, the biases are initialized to
<span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">0</span></span></span></span></span>.</p>

<p>To regularize the models, we add white Gaussian noise of standard
deviation <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0.075</mn></mrow><annotation encoding="application/x-tex">0.075</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">0.075</span></span></span></span></span> to each weight parameter every time the
gradient is computed~<sup class="ref-badge" data-ref="15" data-title="Practical variational inference for neural networks.">15</sup>.</p>

<p>**Language Modeling**: 
We used the same strategy for initializing the parameters in the
case of language modeling. For character-level modeling, the
standard deviations of the white Gaussian distributions for the
input-to-hidden weights and the hidden-to-output weights, we
used <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0.01</mn></mrow><annotation encoding="application/x-tex">0.01</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">0.01</span></span></span></span></span> and <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0.001</mn></mrow><annotation encoding="application/x-tex">0.001</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">0.001</span></span></span></span></span>, respectively, while those hyperparameters 
were both <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0.1</mn></mrow><annotation encoding="application/x-tex">0.1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">0.1</span></span></span></span></span> for word-level modeling. In the case of DOT(S)-RNN, we sample the
weights of between the hidden state and the rectifier
intermediate layer of the output function from the white Gaussian
distribution of standard deviation <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0.01</mn></mrow><annotation encoding="application/x-tex">0.01</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">0.01</span></span></span></span></span>. When using rectifier
units (character-based language modeling) we fix the biases to
<span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0.1</mn></mrow><annotation encoding="application/x-tex">0.1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">0.1</span></span></span></span></span>.</p>

<p>In language modeling, the learning rate starts from an initial
value and is halved each time the validation cost does not
decrease significantly~<sup class="ref-badge" data-ref="33" data-title="(2010).">33</sup>. We do not use any
regularization for the character-level modeling, but for the
word-level modeling we use the same strategy of adding weight
noise as we do with the polyphonic music prediction.</p>

<p>For all the tasks (polyphonic music prediction, character-level
and word-level language modeling), the stacked RNN and the
DOT(S)-RNN were initialized with the weights of the conventional
RNN and the DT(S)-RNN, which is similar to layer-wise pretraining
of a feedforward neural network~\citep[see,
e.g.,][]{Hinton-Science2006}. We use a ten times smaller learning
rate for each parameter that was pretrained as either RNN or
DT(S)-RNN.</p>

<table class="article-table">
  <caption>The performances of the four types of RNNs on the
        polyphonic music prediction. The numbers represent
        negative log-probabilities on test sequences. (*) We
        obtained these results using DOT(S)-RNN with <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mi>p</mi></msub></mrow><annotation encoding="application/x-tex">L_p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">p</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span></span> units
        in the deep transition, maxout units in the deep output
        function and dropout~<sup class="ref-badge" data-ref="19" data-title="Learned-norm pooling for deep feedforward and recurrent neural">19</sup>.</caption>
  <thead><tr>
    <th></th>
    <th>RNN</th>
    <th>DT(S)-RNN</th>
    <th>DOT(S)-RNN</th>
    <th>sRNN</th>
    <th>DOT(S)-RNN*</th>
  </tr></thead>
  <tbody>
  <tr>
    <td>Notthingam</td>
    <td><span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3.225</mn></mrow><annotation encoding="application/x-tex">3.225</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">3.225</span></span></span></span></span></td>
    <td><span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3.206</mn></mrow><annotation encoding="application/x-tex">3.206</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">3.206</span></span></span></span></span></td>
    <td><span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3.215</mn></mrow><annotation encoding="application/x-tex">3.215</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">3.215</span></span></span></span></span></td>
    <td><span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3.258</mn></mrow><annotation encoding="application/x-tex">3.258</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">3.258</span></span></span></span></span></td>
    <td><span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2.95</mn></mrow><annotation encoding="application/x-tex">2.95</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">2.95</span></span></span></span></span></td>
  </tr>
  <tr>
    <td>JSB Chorales</td>
    <td><span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>8.338</mn></mrow><annotation encoding="application/x-tex">8.338</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">8.338</span></span></span></span></span></td>
    <td><span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>8.278</mn></mrow><annotation encoding="application/x-tex">8.278</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">8.278</span></span></span></span></span></td>
    <td><span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>8.437</mn></mrow><annotation encoding="application/x-tex">8.437</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">8.437</span></span></span></span></span></td>
    <td><span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>8.367</mn></mrow><annotation encoding="application/x-tex">8.367</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">8.367</span></span></span></span></span></td>
    <td><span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>7.92</mn></mrow><annotation encoding="application/x-tex">7.92</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">7.92</span></span></span></span></span></td>
  </tr>
  <tr>
    <td>MuseData</td>
    <td><span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>6.990</mn></mrow><annotation encoding="application/x-tex">6.990</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">6.990</span></span></span></span></span></td>
    <td><span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>6.988</mn></mrow><annotation encoding="application/x-tex">6.988</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">6.988</span></span></span></span></span></td>
    <td><span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>6.973</mn></mrow><annotation encoding="application/x-tex">6.973</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">6.973</span></span></span></span></span></td>
    <td><span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>6.954</mn></mrow><annotation encoding="application/x-tex">6.954</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">6.954</span></span></span></span></span></td>
    <td><span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>6.59</mn></mrow><annotation encoding="application/x-tex">6.59</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">6.59</span></span></span></span></span></td>
  </tr>
  </tbody>
</table>

### Result and Analysis

#### Polyphonic Music Prediction

<p>The log-probabilities on the test set of each data are presented
in the first four columns of Tab.~<a href="#tab:result_music" class="cross-ref">Table 2</a>. We were
able to observe that in all cases one of the proposed deep RNNs
outperformed the conventional, shallow RNN. Though, the
suitability of each deep RNN depended on the data it was trained
on.  The best results obtained by the DT(S)-RNNs on Notthingam
and JSB Chorales are close to, but worse than the result obtained
by RNNs trained with the technique of fast dropout (FD) which are
<span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3.09</mn></mrow><annotation encoding="application/x-tex">3.09</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">3.09</span></span></span></span></span> and <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>8.01</mn></mrow><annotation encoding="application/x-tex">8.01</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">8.01</span></span></span></span></span>, respectively~<sup class="ref-badge" data-ref="2" data-title="Smagt, P. (2013).">2</sup>.</p>

<p>In order to quickly investigate whether the proposed deeper
variants of RNNs may also benefit from the recent advances in
feedforward neural networks, such as the use of non-saturating
activation functions
and the method of dropout.  We have built another set of DOT(S)-RNNs that have
the recently proposed <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mi>p</mi></msub></mrow><annotation encoding="application/x-tex">L_p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">p</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span></span> units~<sup class="ref-badge" data-ref="19" data-title="Learned-norm pooling for deep feedforward and recurrent neural">19</sup> in deep transition and
maxout units~<sup class="ref-badge" data-ref="14" data-title="(2013).">14</sup> in deep output function.
Furthermore, we used the method of dropout~<sup class="ref-badge" data-ref="23" data-title="Salakhutdinov, R. (2012b)." data-arxiv-id="1207.0580">23</sup>
instead of weight noise during training. Similarly to the previously trained
models, we searched for the size of the models as well as other learning
hyperparameters that minimize the validation performance. We, however, did not
pretrain these models.</p>

<p>The results obtained by the DOT(S)-RNNs having <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mi>p</mi></msub></mrow><annotation encoding="application/x-tex">L_p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">p</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span></span> and maxout
units trained with dropout are shown in the last column of
Tab.~<a href="#tab:result_music" class="cross-ref">Table 2</a>. On every music dataset the
performance by this model is significantly better than those
achieved by all the other models as well as the best results
reported with recurrent neural networks in <sup class="ref-badge" data-ref="2" data-title="Smagt, P. (2013).">2</sup>.
This suggests us that the proposed variants of deep RNNs also
benefit from having non-saturating activations and using dropout,
just like feedforward neural networks. We reported these results
and more details on the experiment in <sup class="ref-badge" data-ref="19" data-title="Learned-norm pooling for deep feedforward and recurrent neural">19</sup>.</p>

<p>We, however, acknowledge that the model-free state-of-the-art
results for the both datasets were obtained using an RNN combined
with a conditional generative model, such as restricted Boltzmann
machines or neural autoregressive distribution
estimator~\citep[][]{Larochelle+Murray-2011}, in the
output~[Boulanger+al-ICML2012-small].</p>

<table class="article-table">
  <caption>The performances of the four types of RNNs on the
        tasks of language modeling. The numbers represent
        bit-per-character and perplexity computed on test
        sequence, respectively, for the character-level and
        word-level modeling tasks. <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>∗</mo></mrow><annotation encoding="application/x-tex">*</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4653em;"></span><span class="mord">∗</span></span></span></span></span> The previous/current
    state-of-the-art results obtained with shallow RNNs. <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>⋆</mo></mrow><annotation encoding="application/x-tex">\star</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4653em;"></span><span class="mord">⋆</span></span></span></span></span>
The previous/current state-of-the-art results obtained with
RNNs having long-short term memory units.</caption>
  <thead><tr>
    <th></th>
    <th>RNN</th>
    <th>DT(S)-RNN</th>
    <th>DOT(S)-RNN</th>
    <th>sRNN</th>
    <th><span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>∗</mo></mrow><annotation encoding="application/x-tex">*</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4653em;"></span><span class="mord">∗</span></span></span></span></span></th>
    <th><span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>⋆</mo></mrow><annotation encoding="application/x-tex">\star</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4653em;"></span><span class="mord">⋆</span></span></span></span></span></th>
  </tr></thead>
  <tbody>
  <tr>
    <td>Character-Level</td>
    <td><span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1.414</mn></mrow><annotation encoding="application/x-tex">1.414</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1.414</span></span></span></span></span></td>
    <td><span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1.409</mn></mrow><annotation encoding="application/x-tex">1.409</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1.409</span></span></span></span></span></td>
    <td><span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn mathvariant="bold">1.386</mn></mrow><annotation encoding="application/x-tex">\mathbf{1.386}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord"><span class="mord mathbf">1.386</span></span></span></span></span></span></td>
    <td><span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1.412</mn></mrow><annotation encoding="application/x-tex">1.412</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1.412</span></span></span></span></span></td>
    <td><span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1.41</mn></mrow><annotation encoding="application/x-tex">1.41</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1.41</span></span></span></span></span>\footnotemark[1]</td>
    <td><span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1.24</mn></mrow><annotation encoding="application/x-tex">1.24</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1.24</span></span></span></span></span>\footnotemark[3]</td>
  </tr>
  <tr>
    <td>Word-Level</td>
    <td><span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>117.7</mn></mrow><annotation encoding="application/x-tex">117.7</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">117.7</span></span></span></span></span></td>
    <td><span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>112.0</mn></mrow><annotation encoding="application/x-tex">112.0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">112.0</span></span></span></span></span></td>
    <td><span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn mathvariant="bold">107.5</mn></mrow><annotation encoding="application/x-tex">\mathbf{107.5}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord"><span class="mord mathbf">107.5</span></span></span></span></span></span></td>
    <td><span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>110.0</mn></mrow><annotation encoding="application/x-tex">110.0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">110.0</span></span></span></span></span></td>
    <td><span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>123</mn></mrow><annotation encoding="application/x-tex">123</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">123</span></span></span></span></span>\footnotemark[2]</td>
    <td><span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>117</mn></mrow><annotation encoding="application/x-tex">117</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">117</span></span></span></span></span>\footnotemark[3]</td>
  </tr>
  </tbody>
</table>

<p>\footnotetext[1]{Reported by <sup class="ref-badge" data-ref="35" data-title="(2012a).">35</sup> using mRNN with 
Hessian-free optimization technique.}
\footnotetext[2]{Reported by <sup class="ref-badge" data-ref="34" data-title="Extensions of recurrent neural network language model.">34</sup> using
the dynamic evaluation.}
\footnotetext[3]{Reported by <sup class="ref-badge" data-ref="16" data-title="Generating sequences with recurrent neural networks.">16</sup> using the dynamic
evaluation and weight noise.}</p>

#### Language Modeling

<p>On Tab.~<a href="#tab:result_lm_penn" class="cross-ref">Table 3</a>, we can see the perplexities on
the test set achieved by the all four models. We can clearly see
that the deep RNNs (DT(S)-RNN, DOT(S)-RNN and sRNN) outperform
the conventional, shallow RNN significantly.  On these tasks
DOT(S)-RNN outperformed all the other models, which suggests that
it is important to have highly nonlinear mapping from the hidden
state to the output in the case of language modeling.</p>

<p>The results by both the DOT(S)-RNN and the sRNN for word-level
modeling surpassed the previous best performance achieved by an
RNN with 1000 long short-term memory (LSTM) units~<sup class="ref-badge" data-ref="16" data-title="Generating sequences with recurrent neural networks.">16</sup> as well as that by a shallow RNN with a larger
hidden state~<sup class="ref-badge" data-ref="34" data-title="Extensions of recurrent neural network language model.">34</sup>, even when both of them
used dynamic evaluation. The results we report here are without
dynamic evaluation.</p>

<p>For character-level modeling the state-of-the-art results were
obtained using an optimization method Hessian-free with a specific type of
RNN architecture called mRNN~<sup class="ref-badge" data-ref="35" data-title="(2012a).">35</sup> or a regularization
technique called adaptive weight noise~<sup class="ref-badge" data-ref="16" data-title="Generating sequences with recurrent neural networks.">16</sup>. Our result, however, 
is better than the performance achieved by conventional, 
shallow RNNs without any of those advanced regularization methods~<sup class="ref-badge" data-ref="36" data-title="J. (2012b).">36</sup>, where they reported the best
performance of <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1.41</mn></mrow><annotation encoding="application/x-tex">1.41</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1.41</span></span></span></span></span> using an RNN trained with the Hessian-free
learning algorithm~[Martens+Sutskever-ICML2011].</p>

<hr>

<h2>6. Discussion</h2>

<span id="sec:final" class="label-anchor"></span>

<p>In this paper, we have explored a novel approach to building a
deep recurrent neural network (RNN). We considered the structure
of an RNN at each timestep, which revealed that the relationship
between the consecutive hidden states and that between the hidden
state and output are *shallow*. Based on this observation,
we proposed two alternative designs of *deep* RNN that
make those *shallow* relationships be modeled by deep
neural networks. Furthermore, we proposed to make use of shortcut
connections in these deep RNNs to alleviate a problem of
difficult learning potentially introduced by the increasing
depth.</p>

<p>We empirically evaluated the proposed designs against the
conventional RNN which has only a single hidden layer and against
another approach of building a deep RNN~\citep[stacked
RNN,][]{Graves2013}, on the task of polyphonic music prediction
and language modeling.</p>

<p>The experiments revealed that the RNN with the proposed deep
transition and deep output (DOT(S)-RNN) outperformed both the
conventional RNN and the stacked RNN on the task of language
modeling, achieving the state-of-the-art result on the task of
word-level language modeling. For polyphonic music prediction, a
different deeper variant of an RNN achieved the best performance
for each dataset. Importantly, however, in all the cases, the
conventional, shallow RNN was not able to outperform the deeper
variants.  These results strongly support our claim that an RNN
benefits from having a deeper architecture, just like feedforward
neural networks.</p>

<p>The observation that there is no clear winner in the task of
polyphonic music prediction suggests us that each of the proposed
deep RNNs has a distinct characteristic that makes it more, or
less, suitable for certain types of datasets. We suspect that in
the future it will be possible to design and train yet another
deeper variant of an RNN that combines the proposed models
together to be more robust to the characteristics of datasets.
For instance, a stacked DT(S)-RNN may be constructed by combining
the DT(S)-RNN and the sRNN.</p>

<p>In a quick additional experiment where we have trained DOT(S)-RNN
constructed using non-saturating nonlinear activation functions
and trained with the method of dropout, we were able to improve
the performance of the deep recurrent neural networks on the
polyphonic music prediction tasks significantly. This suggests us
that it is important to investigate the possibility of applying
recent advances in feedforward neural networks, such as novel,
non-saturating activation functions and the method of dropout, to
recurrent neural networks as well. However, we leave this as
future research.</p>

<p>One practical issue we ran into during the experiments was the
difficulty of training deep RNNs. We were able to train the
conventional RNN as well as the DT(S)-RNN easily, but it was not
trivial to train the DOT(S)-RNN and the stacked RNN. In this
paper, we proposed to use shortcut connections as well as to
pretrain them either with the conventional RNN or with the
DT(S)-RNN. We, however, believe that learning may become even
more problematic as the size and the depth of a model increase.
In the future, it will be important to investigate the root
causes of this difficulty and to explore potential solutions.  We
find some of the recently introduced approaches, such as advanced
regularization methods~[Pascanu+al-ICML2013-small] and
advanced optimization algorithms~\citep[see,
e.g.,][]{Pascanu+Bengio-arxiv2013,martens2010hessian}, to be
promising candidates.</p>

<p>{
#### Acknowledgments
We would like to thank the developers of
Theano~[bergstra+al:2010-scipy]<sup class="ref-badge" data-ref="1" data-title="Bergeron, A., Bouchard, N., and Bengio, Y. (2012).">1</sup>.  We
also thank Justin Bayer for his insightful comments on the paper.
We would like to thank NSERC, Compute Canada, and Calcul Qu\'ebec
for providing computational resources. Razvan Pascanu is
supported by a DeepMind Fellowship.  Kyunghyun Cho is supported
by FICS (Finnish Doctoral Programme in Computational Sciences)
and ``the Academy of Finland (Finnish Centre of Excellence in
Computational Inference Research COIN, 251170)''.</p>

<p>\newpage</p>

<p>\bibliography{strings,strings-short,strings-shorter,aigaion-shorter,ml,myref}</p>

<p>\bibliographystyle{natbib}
}</p>

<hr>

<h2>References</h2>
<ol class="references">
  <li id="ref-1"><strong>Bastien, F., Lamblin, P., Pascanu, R., Bergstra, J., Goodfellow, I. J.,</strong> Bergeron, A., Bouchard, N., and Bengio, Y. (2012).. <em>Theano: new features and speed improvements. Deep Learning and Unsupervised Feature Learning NIPS 2012 Workshop.</em></li>
  <li id="ref-2"><strong>Bayer, J., Osendorfer, C., Korhammer, D., Chen, N., Urban, S., and van der</strong> Smagt, P. (2013).. <em>On fast dropout and its applicability to recurrent networks. arXiv:\tt 1311.0701 [cs.NE]\/.</em></li>
  <li id="ref-3"><strong>Bengio, Y. (2009).</strong> Learning deep architectures for AI.. <em>Found. Trends Mach. Learn., \bf 2(1), 1--127.</em></li>
  <li id="ref-4"><strong>Bengio, Y., Simard, P., and Frasconi, P. (1994).</strong> Learning long-term dependencies with gradient descent is difficult.. <em>IEEE Transactions on Neural Networks\/, \bf 5(2), 157--166.</em></li>
  <li id="ref-5"><strong>Bengio, Y., Mesnil, G., Dauphin, Y., and Rifai, S. (2013).</strong> Better mixing via deep representations.. <em>In ICML'13\/.</em></li>
  <li id="ref-6"><strong>Bergstra, J., Breuleux, O., Bastien, F., Lamblin, P., Pascanu, R., Desjardins,</strong> G., Turian, J., Warde-Farley, D., and Bengio, Y. (2010).. <em>Theano: a CPU and GPU math expression compiler. In Proceedings of the Python for Scientific Computing Conference (SciPy)\/. Oral Presentation.</em></li>
  <li id="ref-7"><strong>Boulanger-Lewandowski, N., Bengio, Y., and Vincent, P. (2012).</strong> Modeling temporal dependencies in high-dimensional sequences:. <em>Application to polyphonic music generation and transcription. In ICML'2012\/.</em></li>
  <li id="ref-8"><strong>Chen, J. and Deng, L. (2013).</strong> A new method for learning deep recurrent neural networks.. <em>arXiv:\tt 1311.6091 [cs.LG]\/.</em></li>
  <li id="ref-9"><strong>Delalleau, O. and Bengio, Y. (2011).</strong> Shallow vs. deep sum-product networks.. <em>In NIPS\/.</em></li>
  <li id="ref-10"><strong>El Hihi, S. and Bengio, Y. (1996).</strong> Hierarchical recurrent neural networks for long-term dependencies.. <em>In NIPS 8\/. MIT Press.</em></li>
  <li id="ref-11"><strong>Glorot, X., Bordes, A., and Bengio, Y. (2011a).</strong> Deep sparse rectifier neural networks.. <em>In AISTATS\/.</em></li>
  <li id="ref-12"><strong>Glorot, X., Bordes, A., and Bengio, Y. (2011b).</strong> Domain adaptation for large-scale sentiment classification: A deep. <em>learning approach. In ICML'2011\/.</em></li>
  <li id="ref-13"><strong>Goodfellow, I., Le, Q., Saxe, A., and Ng, A. (2009).</strong> Measuring invariances in deep networks.. <em>In NIPS'09\/, pages 646--654.</em></li>
  <li id="ref-14"><strong>Goodfellow, I. J., Warde-Farley, D., Mirza, M., Courville, A., and Bengio, Y.</strong> (2013).. <em>Maxout networks. In ICML'2013\/.</em></li>
  <li id="ref-15"><strong>Graves, A. (2011).</strong> Practical variational inference for neural networks.. <em>In J. Shawe-Taylor, R. Zemel, P. Bartlett, F. Pereira, and K. Weinberger, editors, Advances in Neural Information Processing Systems 24\/, pages 2348--2356.</em></li>
  <li id="ref-16"><strong>Graves, A. (2013).</strong> Generating sequences with recurrent neural networks.. <em>arXiv:\tt 1308.0850 [cs.NE]\/.</em></li>
  <li id="ref-17"><strong>Graves, A., Liwicki, M., Fernandez, S., Bertolami, R., Bunke, H., and</strong> Schmidhuber, J. (2009).. <em>A novel connectionist system for improved unconstrained handwriting recognition. IEEE Transactions on Pattern Analysis and Machine Intelligence\/.</em></li>
  <li id="ref-18"><strong>Graves, A., Mohamed, A., and Hinton, G. (2013).</strong> Speech recognition with deep recurrent neural networks.. <em>ICASSP\/.</em></li>
  <li id="ref-19"><strong>Gulcehre, C., Cho, K., Pascanu, R., and Bengio, Y. (2013).</strong> Learned-norm pooling for deep feedforward and recurrent neural. <em>networks. arXiv:\tt 1311.1780 [cs.NE]\/.</em></li>
  <li id="ref-20"><strong>Hermans, M. and Schrauwen, B. (2013).</strong> Training and analysing deep recurrent neural networks.. <em>In Advances in Neural Information Processing Systems 26\/, pages 190--198.</em></li>
  <li id="ref-21"><strong>Hinton, G., Deng, L., Dahl, G. E., Mohamed, A., Jaitly, N., Senior, A.,</strong> Vanhoucke, V., Nguyen, P., Sainath, T., and Kingsbury, B. (2012a).. <em>Deep neural networks for acoustic modeling in speech recognition. IEEE Signal Processing Magazine\/, \bf 29(6), 82--97.</em></li>
  <li id="ref-22"><strong>Hinton, G. E. and Salakhutdinov, R. (2006).</strong> Reducing the dimensionality of data with neural networks.. <em>Science\/, \bf 313(5786), 504--507.</em></li>
  <li id="ref-23"><strong>Hinton, G. E., Srivastava, N., Krizhevsky, A., Sutskever, I., and</strong> Salakhutdinov, R. (2012b).. <em>Improving neural networks by preventing co-adaptation of feature detectors. Technical report, arXiv:1207.0580.</em></li>
  <li id="ref-24"><strong>Hornik, K., Stinchcombe, M., and White, H. (1989).</strong> Multilayer feedforward networks are universal approximators.. <em>Neural Networks\/, \bf 2, 359--366.</em></li>
  <li id="ref-25"><strong>Jaeger, H. (2007).</strong> Discovering multiscale dynamical features with hierarchical echo. <em>state networks. Technical report, Jacobs University.</em></li>
  <li id="ref-26"><strong>Ko, J. and Dieter, F. (2009).</strong> Gp-bayesfilters: Bayesian filtering using gaussian process prediction. <em>and observation models. Autonomous Robots\/.</em></li>
  <li id="ref-27"><strong>Larochelle, H. and Murray, I. (2011).</strong> The Neural Autoregressive Distribution Estimator.. <em>In Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics (AISTATS'2011)\/, volume 15 of JMLR: W\&CP.</em></li>
  <li id="ref-28"><strong>Le Roux, N. and Bengio, Y. (2010).</strong> Deep belief networks are compact universal approximators.. <em>Neural Computation\/, \bf 22(8), 2192--2207.</em></li>
  <li id="ref-29"><strong>Marcus, M. P., Marcinkiewicz, M. A., and Santorini, B. (1993).</strong> Building a large annotated corpus of english: The Penn Treebank.. <em>Computational Linguistics\/, \bf 19(2), 313--330.</em></li>
  <li id="ref-30"><strong>Martens, J. (2010).</strong> Deep learning via Hessian-free optimization.. <em>In L. Bottou and M. Littman, editors, Proceedings of the Twenty-seventh International Conference on Machine Learning (ICML-10)\/, pages 735--742. ACM.</em></li>
  <li id="ref-31"><strong>Martens, J. and Sutskever, I. (2011).</strong> Learning recurrent neural networks with Hessian-free optimization.. <em>In Proc. ICML'2011\/. ACM.</em></li>
  <li id="ref-32"><strong>Mikolov, T. (2012).</strong> Statistical Language Models based on Neural Networks\/.. <em>Ph.D. thesis, Brno University of Technology.</em></li>
  <li id="ref-33"><strong>Mikolov, T., Karafi\'at, M., Burget, L., Cernocky, J., and Khudanpur, S.</strong> (2010).. <em>Recurrent neural network based language model. In Proceedings of the 11th Annual Conference of the International Speech Communication Association (INTERSPEECH 2010)\/, volume 2010, pages 1045--1048. International Speech Communication Association.</em></li>
  <li id="ref-34"><strong>Mikolov, T., Kombrink, S., Burget, L., Cernocky, J., and Khudanpur, S. (2011).</strong> Extensions of recurrent neural network language model.. <em>In Proc. 2011 IEEE international conference on acoustics, speech and signal processing (ICASSP 2011)\/.</em></li>
  <li id="ref-35"><strong>Mikolov, T., Sutskever, I., Deoras, A., Le, H., Kombrink, S., and Cernocky, J.</strong> (2012a).. <em>Subword language modeling with neural networks. unpublished\/.</em></li>
  <li id="ref-36"><strong>Mikolov, T., Sutskever, I., Deoras, A., Le, H.-S., Kombrink, S., and Cernocky,</strong> J. (2012b).. <em>Subword language modeling with neural networks. preprint (http://www.fit.vutbr.cz/ imikolov/rnnlm/char.pdf).</em></li>
  <li id="ref-37"><strong>Mikolov, T., Sutskever, I., Chen, K., Corrado, G., and Dean, J. (2013a).</strong> Distributed representations of words and phrases and their. <em>compositionality. In Advances in Neural Information Processing Systems 26\/, pages 3111--3119.</em></li>
  <li id="ref-38"><strong>Mikolov, T., Chen, K., Corrado, G., and Dean, J. (2013b).</strong> Efficient estimation of word representations in vector space.. <em>In International Conference on Learning Representations: Workshops Track\/.</em></li>
  <li id="ref-39"><strong>Pascanu, R. and Bengio, Y. (2013).</strong> Revisiting natural gradient for deep networks.. <em>Technical report, arXiv:1301.3584.</em></li>
  <li id="ref-40"><strong>Pascanu, R., Mikolov, T., and Bengio, Y. (2013a).</strong> On the difficulty of training recurrent neural networks.. <em>In ICML'2013\/.</em></li>
  <li id="ref-41"><strong>Pascanu, R., Montufar, G., and Bengio, Y. (2013b).</strong> On the number of response regions of deep feed forward networks with. <em>piece-wise linear activations. arXiv:\tt 1312.6098[cs.LG]\/.</em></li>
  <li id="ref-42"><strong>Pinheiro, P. and Collobert, R. (2014).</strong> Recurrent convolutional neural networks for scene labeling.. <em>In Proceedings of The 31st International Conference on Machine Learning\/, pages 82--90.</em></li>
  <li id="ref-43"><strong>Raiko, T., Valpola, H., and LeCun, Y. (2012).</strong> Deep learning made easier by linear transformations in perceptrons.. <em>In Proceedings of the Fifteenth Internation Conference on Artificial Intelligence and Statistics (AISTATS 2012)\/, volume 22 of JMLR Workshop and Conference Proceedings\/, pages 924--932. JMLR W\&CP.</em></li>
  <li id="ref-44"><strong>Rumelhart, D. E., Hinton, G. E., and Williams, R. J. (1986).</strong> Learning representations by back-propagating errors.. <em>Nature\/, \bf 323, 533--536.</em></li>
  <li id="ref-45"><strong>Schmidhuber, J. (1992).</strong> Learning complex, extended sequences using the principle of history. <em>compression. Neural Computation\/, (4), 234--242.</em></li>
  <li id="ref-46"><strong>Sutskever, I., Martens, J., and Hinton, G. (2011).</strong> Generating text with recurrent neural networks.. <em>In L. Getoor and T. Scheffer, editors, Proceedings of the 28th International Conference on Machine Learning (ICML 2011)\/, pages 1017--1024, New York, NY, USA. ACM.</em></li>
  <li id="ref-47"><strong>Sutskever, I., Martens, J., Dahl, G., and Hinton, G. (2013).</strong> On the importance of initialization and momentum in deep learning.. <em>In ICML\/.</em></li>
  <li id="ref-48"><strong>Valpola, H. and Karhunen, J. (2002).</strong> An unsupervised ensemble learning method for nonlinear dynamic. <em>state-space models. Neural Comput., \bf 14(11), 2647--2692. \endthebibliography</em></li>
</ol>

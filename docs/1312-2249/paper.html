<h1>Scalable Object Detection using Deep Neural Networks</h1>

<p class="authors">szegedy, toshev, dragomir\</p>

<h2>Abstract</h2>
<p>Deep convolutional neural networks have recently achieved
  state-of-the-art performance on a number of image recognition benchmarks,
  including the ImageNet Large-Scale Visual Recognition Challenge
  (ILSVRC-2012).  The winning model on the localization sub-task was a network
  that predicts a single bounding box and a confidence score for each object
  category in the image. Such a model captures the whole-image context around
  the objects but cannot handle multiple instances of the same object in the
  image without naively replicating the number of outputs for each instance.
  In this work, we propose a saliency-inspired neural network model for
  detection, which predicts a set of class-agnostic bounding boxes along with a
  single score for each box, corresponding to its likelihood of containing
  \textit{any} object of interest. The model naturally handles a variable
  number of instances for each class and allows for cross-class generalization
  at the highest levels of the network. We are able to obtain competitive
  recognition performance on VOC2007 and ILSVRC2012, while using only the top
  few predicted locations in each image and a small number of neural network
  evaluations.</p>

<hr>

<h2>1. Introduction</h2>

<p>Object detection is one of the fundamental tasks in computer vision. A common
paradigm to address this problem is to train object detectors which operate on
a subimage and apply these detectors in an exhaustive manner across all locations
and scales. This paradigm was successfully used within a discriminatively trained
Deformable Part Model (DPM) to achieve state-of-art results on detection tasks
[felzenszwalb2010object].</p>

<p>The exhaustive search through all possible locations and scales poses a computational
challenge. This challenge becomes even harder as the number of classes grows, since
most of the approaches train a separate detector per class. In order to address this issue
a variety of methods were proposed, varying from detector cascades, to using segmentation
to suggest a small number of object hypotheses
[van2011segmentation][carreira2010constrained][endres2010category].</p>

<p>In this paper, we ascribe to the latter philosphy and propose to train a detector, called ``DeepMultiBox'','
which generates a few bounding boxes as object candidates. These boxes are
generated by a *single* DNN in a *class agnostic* manner. Our model
has several contributions. First, we define object detection as a regression problem
to the coordinates of several bounding boxes. In addition, for each predicted box
the net outputs a confidence score of how likely this box contains an object.
This is quite different from traditional approaches, which
score features within predefined boxes, and has the advantage of expressing
detection of objects in a very compact and efficient way.</p>

<p>The second major contribution is the loss, which trains the bounding box predictors
as part of the network training. For each training example, we solve an assignment
problem between the current predictions and the groundtruth boxes and update the matched
box coordinates, their confidences and the underlying features through Backpropagation. In this
way, we learn a deep net tailored towards our localization problem. We
capitalize on the excellent representation learning abilities of DNNs, as recently
exeplified recently in image classification [krizhevsky2012imagenet] and
object detection settings [szegedy2013detection], and perform joint learning of
representation and predictors.</p>

<p>Finally, we train our object box predictor in a class-agnostic manner. We consider this
as a scalable way to enable efficient detection of large number of object classes. We
show in our experiments that by only post-classifying less than ten boxes, obtained by
a single network application, we can achieve state-of-art detection results. Further, we
show that our box predictor generalizes over unseen classes and as such is flexible to be
re-used within other detection problems.</p>

<hr>

<h2>2. Previous work</h2>

<p>The literature on object detection is vast, and in this section we will
focus on approaches exploiting class-agnostic ideas and addressing scalability.</p>

<p>Many of the proposed detection approaches are based on part-based models [fischler1973representation],
which more recently have achieved
impressive performance thanks to discriminative learning and carefully
crafted features [felzenszwalb2010object]. These methods, however, rely on
exhaustive application of part templates over multiple scales and as such are expensive.
Moreover, they scale linearly in the number of classes, which becomes a
challenge for modern datasets such as ImageNet.</p>

<p>To address the former issue, Lampert et al.~[lampert2008beyond] use a
branch-and-bound strategy to avoid evaluating all potential object locations.
To address the latter issue, Song et al.~[song2012sparselet] use a
low-dimensional part basis, shared across all object classes. A hashing based
approach for efficient part detection has shown good results as well
[dean2013fast].</p>

<p>A different line of work, closer to ours, is based on the idea that objects
can be localized *without* having to know their class. Some
of these approaches build on bottom-up classless segmentation [gu2009recognition].
The segments, obtained in this way, can be scored using top-down feedback
[van2011segmentation][carreira2010constrained][endres2010category].  Using the same
motivation, Alexe et al.~[alexe2010object] use an inexpensive classifier to
score object hypotheses for being an object or not and in this way reduce the
number of location for the subsequent detection steps. These
approaches can be thought of as Multi-layered models, with segmentation as first
layer and a segment classification as a subsequent layer. Despite the fact that
they encode proven perceptual principles, we will show that having deeper
models which are fully learned can lead to superior results.</p>

<p>Finally, we capitalize on the recent advances in Deep Learning, most noticeably
the work by Krizhevsky et al.~[krizhevsky2012imagenet]. We extend their
bounding box regression approach for detection to the case of handling
multiple objects in a scalable manner. DNN-based regression, to object
masks however, has been applied by Szegedy et al.~[szegedy2013detection]. 
This last approach achieves state-of-art detection performance but does not 
scale up to multiple classes due to the cost of a single mask regression.</p>

<hr>

<h2>3. Proposed approach</h2>

<p>We aim at achieving a class-agnostic scalable object detection by predicting
a set of bounding boxes, which represent potential objects. More precisely, we
use a Deep Neural Network (DNN), which outputs a fixed number of bounding boxes.
In addition, it outputs a score for each box expressing the networkconfidence of
this box containing an object.</p>

<p>\vspace{-0.5cm}
**Model.** To formalize the above idea, we encode the <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6595em;"></span><span class="mord mathnormal">i</span></span></span></span></span>-th object box and its
associated confidence as node values of the last net layer:
\begin{description}
\item[Bounding box:] we encode the upper-left and lower-right coordinates of
each box as four node values, which can be written as a vector
<span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>l</mi><mi>i</mi></msub><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mn>4</mn></msup></mrow><annotation encoding="application/x-tex">l_i\in\mathbb{R}^4</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0197em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8141em;"></span><span class="mord"><span class="mord mathbb">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">4</span></span></span></span></span></span></span></span></span></span></span></span>. These coordinates are normalized w. r. t. image dimensions
to achieve invariance to absolute image size. Each normalized coordinate is
produced by a linear transformation of the last hidden layer.
\item[Confidence:] the confidence score for the box containing an object is encoded as
a single node value <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>c</mi><mi>i</mi></msub><mo>∈</mo><mo stretchy="false">[</mo><mn>0</mn><mo separator="true">,</mo><mn>1</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">c_i\in[0, 1]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6891em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">1</span><span class="mclose">]</span></span></span></span></span>. This value is produced through a linear transformation
of the last hidden layer followed by a sigmoid.
\end{description}
We can combine the bounding box locations <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>l</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">l_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0197em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span>, <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi><mo>∈</mo><mo stretchy="false">{</mo><mn>1</mn><mo separator="true">,</mo><mo>…</mo><mi>K</mi><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">i\in\{1,\ldots K\}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6986em;vertical-align:-0.0391em;"></span><span class="mord mathnormal">i</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">{</span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="var" data-var="K" data-desc="Key matrix — packed keys (shape: seq_len × d_k)" style="--var-color: #58a6ff"><span class="mord mathnormal" style="margin-right:0.07153em;">K</span></span><span class="mclose">}</span></span></span></span></span>, as one
linear layer. Similarly, we can treat collection of all confidences <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>c</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">c_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span>,
<span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi><mo>∈</mo><mo stretchy="false">{</mo><mn>1</mn><mo separator="true">,</mo><mo>…</mo><mi>K</mi><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">i\in\{1,\ldots K\}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6986em;vertical-align:-0.0391em;"></span><span class="mord mathnormal">i</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">{</span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="var" data-var="K" data-desc="Key matrix — packed keys (shape: seq_len × d_k)" style="--var-color: #58a6ff"><span class="mord mathnormal" style="margin-right:0.07153em;">K</span></span><span class="mclose">}</span></span></span></span></span> as the output as one sigmoid layer. Both these output layers are
connected to the last hidden layers.</p>

<p>At inference time, out algorithm produces <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="var" data-var="K" data-desc="Key matrix — packed keys (shape: seq_len × d_k)" style="--var-color: #58a6ff"><span class="mord mathnormal" style="margin-right:0.07153em;">K</span></span></span></span></span></span> bounding boxes. In our experiments,
we use <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi><mo>=</mo><mn>100</mn></mrow><annotation encoding="application/x-tex">K=100</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="var" data-var="K" data-desc="Key matrix — packed keys (shape: seq_len × d_k)" style="--var-color: #58a6ff"><span class="mord mathnormal" style="margin-right:0.07153em;">K</span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">100</span></span></span></span></span> and <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi><mo>=</mo><mn>200</mn></mrow><annotation encoding="application/x-tex">K=200</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="var" data-var="K" data-desc="Key matrix — packed keys (shape: seq_len × d_k)" style="--var-color: #58a6ff"><span class="mord mathnormal" style="margin-right:0.07153em;">K</span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">200</span></span></span></span></span>. If desired, we can use the confidence scores and non-maximum
suppression to obtain a smaller
number of high-confidence boxes at inference time. These boxes
are supposed to represent objects. As such, they can be classified with a
subsequent classifier to achieve object detection. Since the number of boxes is
very small, we can afford powerful classifiers. In our
experiments, we use another DNN for classification [krizhevsky2012imagenet].</p>

<p>\vspace{-0.5cm}
**Training Objective.** We train a DNN to predict bounding boxes and
their confidence scores for each training image such that the highest scoring
boxes match well the ground truth object boxes for the image.
Suppose that for a particular training example, <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi></mrow><annotation encoding="application/x-tex">M</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span></span></span></span></span>
objects were labeled by bounding boxes <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>g</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">g_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7167em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span></span>, <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>j</mi><mo>∈</mo><mo stretchy="false">{</mo><mn>1</mn><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><mi>M</mi><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">j\in\{1,\ldots, M\}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.854em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.05724em;">j</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">{</span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mclose">}</span></span></span></span></span>. In
practice, the number of predictions <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="var" data-var="K" data-desc="Key matrix — packed keys (shape: seq_len × d_k)" style="--var-color: #58a6ff"><span class="mord mathnormal" style="margin-right:0.07153em;">K</span></span></span></span></span></span> is much larger than the number of
groundtruth boxes <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi></mrow><annotation encoding="application/x-tex">M</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span></span></span></span></span>. Therefore, we try to optimize only the subset of predicted
boxes which match best the ground truth ones. We optimize their locations to
improve their match and maximize their confidences. At the
same time we minimize the confidences of the remaining predictions, which are
deemed not to localize the true objects well.</p>

<p>To achieve the above, we formulate an assignment problem
for each training example. We <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>∈</mo><mo stretchy="false">{</mo><mn>0</mn><mo separator="true">,</mo><mn>1</mn><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">x_{ij}\in\{0,1\}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8252em;vertical-align:-0.2861em;"></span><span class="mord"><span class="var" data-var="x" data-desc="Input tensor" style="--var-color: #98c379"><span class="mord mathnormal">x</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">ij</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">{</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">1</span><span class="mclose">}</span></span></span></span></span> denote the assignment:
<span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">x_{ij} = 1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7167em;vertical-align:-0.2861em;"></span><span class="mord"><span class="var" data-var="x" data-desc="Input tensor" style="--var-color: #98c379"><span class="mord mathnormal">x</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">ij</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1</span></span></span></span></span> iff the <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6595em;"></span><span class="mord mathnormal">i</span></span></span></span></span>-th prediction is assigned to <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>j</mi></mrow><annotation encoding="application/x-tex">j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.854em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.05724em;">j</span></span></span></span></span>-th true object. The
objective of this assignment can be expressed as:</p>

<div class="math-display"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mo>&lt;</mo><mi>s</mi><mi>p</mi><mi>a</mi><mi>n</mi><mi>i</mi><mi>d</mi><mo>=</mo><mi mathvariant="normal">&quot;</mi><mi>e</mi><mi>q</mi><mo>:</mo><mi>a</mi><mi>s</mi><mi>s</mi><mi>i</mi><mi>g</mi><mi>n</mi><mi>m</mi><mi>e</mi><mi>n</mi><msub><mi>t</mi><mi>o</mi></msub><mi>b</mi><mi>j</mi><mi>e</mi><mi>c</mi><mi>t</mi><mi>i</mi><mi>v</mi><mi>e</mi><mi mathvariant="normal">&quot;</mi><mi>c</mi><mi>l</mi><mi>a</mi><mi>s</mi><mi>s</mi><mo>=</mo><mi mathvariant="normal">&quot;</mi><mi>l</mi><mi>a</mi><mi>b</mi><mi>e</mi><mi>l</mi><mo>−</mo><mi>a</mi><mi>n</mi><mi>c</mi><mi>h</mi><mi>o</mi><mi>r</mi><mi mathvariant="normal">&quot;</mi><mo>&gt;</mo><mo>&lt;</mo><mi mathvariant="normal">/</mi><mi>s</mi><mi>p</mi><mi>a</mi><mi>n</mi><mo>&gt;</mo><msub><mi>F</mi><mtext>match</mtext></msub><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>l</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><munder><mo>∑</mo><mrow><mi>i</mi><mo separator="true">,</mo><mi>j</mi></mrow></munder><msub><mi>x</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mi mathvariant="normal">∣</mi><mi mathvariant="normal">∣</mi><msub><mi>l</mi><mi>i</mi></msub><mo>−</mo><msub><mi>g</mi><mi>j</mi></msub><mi mathvariant="normal">∣</mi><msubsup><mi mathvariant="normal">∣</mi><mn>2</mn><mn>2</mn></msubsup></mrow><annotation encoding="application/x-tex">&lt;span id=&quot;eq:assignment_objective&quot; class=&quot;label-anchor&quot;&gt;&lt;/span&gt;
  F_{\text{match}}(x, l)=\frac{1}{2}\sum_{i,j}x_{ij}||l_i-g_j||_2^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5782em;vertical-align:-0.0391em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">s</span><span class="mord mathnormal">p</span><span class="mord mathnormal">ani</span><span class="mord mathnormal">d</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord">&quot;</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">a</span><span class="mord mathnormal">ss</span><span class="mord mathnormal">i</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord mathnormal">nm</span><span class="mord mathnormal">e</span><span class="var" data-var="n" data-desc="Sequence length" style="--var-color: #c678dd"><span class="mord mathnormal">n</span></span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">o</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord mathnormal" style="margin-right:0.05724em;">bj</span><span class="mord mathnormal">ec</span><span class="mord mathnormal">t</span><span class="mord mathnormal">i</span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mord mathnormal">e</span><span class="mord">&quot;</span><span class="mord mathnormal">c</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">a</span><span class="mord mathnormal">ss</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.7778em;vertical-align:-0.0833em;"></span><span class="mord">&quot;</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">ab</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.7335em;vertical-align:-0.0391em;"></span><span class="mord mathnormal">an</span><span class="mord mathnormal">c</span><span class="var" data-var="h" data-desc="Number of parallel attention heads (h = 8)" style="--var-color: #ff7b72"><span class="mord mathnormal">h</span></span><span class="mord mathnormal" style="margin-right:0.02778em;">or</span><span class="mord">&quot;</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">&gt;&lt;</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">/</span><span class="mord mathnormal">s</span><span class="mord mathnormal">p</span><span class="mord mathnormal">an</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">&gt;</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">F</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">match</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="var" data-var="x" data-desc="Input tensor" style="--var-color: #98c379"><span class="mord mathnormal">x</span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.7352em;vertical-align:-1.4138em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3214em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.05em;"><span style="top:-1.8723em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.4138em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="var" data-var="x" data-desc="Input tensor" style="--var-color: #98c379"><span class="mord mathnormal">x</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">ij</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mord">∣∣</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0197em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.1502em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mord">∣</span><span class="mord"><span class="mord">∣</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8641em;"><span style="top:-2.453em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span></span></span></span></span></div>

<p>where we use <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">L_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span> distance between the normalized bounding box coordinates to
quantify the dissimilarity between bounding boxes.</p>

<p>Additionally, we want to optimize the confidences of the boxes according to the
assignment <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="var" data-var="x" data-desc="Input tensor" style="--var-color: #98c379"><span class="mord mathnormal">x</span></span></span></span></span></span>. Maximizing the confidences of assigned predictions
can be expressed as:</p>

<div class="math-display"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mo>&lt;</mo><mi>s</mi><mi>p</mi><mi>a</mi><mi>n</mi><mi>i</mi><mi>d</mi><mo>=</mo><mi mathvariant="normal">&quot;</mi><mi>e</mi><mi>q</mi><mo>:</mo><mi>c</mi><mi>o</mi><mi>n</mi><mi>f</mi><mi>i</mi><mi>d</mi><mi>e</mi><mi>n</mi><mi>c</mi><msub><mi>e</mi><mi>o</mi></msub><mi>b</mi><mi>j</mi><mi>e</mi><mi>c</mi><mi>t</mi><mi>i</mi><mi>v</mi><mi>e</mi><mi mathvariant="normal">&quot;</mi><mi>c</mi><mi>l</mi><mi>a</mi><mi>s</mi><mi>s</mi><mo>=</mo><mi mathvariant="normal">&quot;</mi><mi>l</mi><mi>a</mi><mi>b</mi><mi>e</mi><mi>l</mi><mo>−</mo><mi>a</mi><mi>n</mi><mi>c</mi><mi>h</mi><mi>o</mi><mi>r</mi><mi mathvariant="normal">&quot;</mi><mo>&gt;</mo><mo>&lt;</mo><mi mathvariant="normal">/</mi><mi>s</mi><mi>p</mi><mi>a</mi><mi>n</mi><mo>&gt;</mo><msub><mi>F</mi><mtext>conf</mtext></msub><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>c</mi><mo stretchy="false">)</mo><mo>=</mo><mo>−</mo><munder><mo>∑</mo><mrow><mi>i</mi><mo separator="true">,</mo><mi>j</mi></mrow></munder><msub><mi>x</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mi>log</mi><mo>⁡</mo><mo stretchy="false">(</mo><msub><mi>c</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>−</mo><munder><mo>∑</mo><mi>i</mi></munder><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><munder><mo>∑</mo><mi>j</mi></munder><msub><mi>x</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo stretchy="false">)</mo><mi>log</mi><mo>⁡</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><msub><mi>c</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">&lt;span id=&quot;eq:confidence_objective&quot; class=&quot;label-anchor&quot;&gt;&lt;/span&gt;
F_{\text{conf}}(x, c)=-\sum_{i,j}x_{ij}\log(c_i) - \sum_i(1-\sum_jx_{ij})\log(1-c_i)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5782em;vertical-align:-0.0391em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">s</span><span class="mord mathnormal">p</span><span class="mord mathnormal">ani</span><span class="mord mathnormal">d</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord">&quot;</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">co</span><span class="var" data-var="n" data-desc="Sequence length" style="--var-color: #c678dd"><span class="mord mathnormal">n</span></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mord mathnormal">i</span><span class="mord mathnormal">d</span><span class="mord mathnormal">e</span><span class="var" data-var="n" data-desc="Sequence length" style="--var-color: #c678dd"><span class="mord mathnormal">n</span></span><span class="mord mathnormal">c</span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">o</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord mathnormal" style="margin-right:0.05724em;">bj</span><span class="mord mathnormal">ec</span><span class="mord mathnormal">t</span><span class="mord mathnormal">i</span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mord mathnormal">e</span><span class="mord">&quot;</span><span class="mord mathnormal">c</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">a</span><span class="mord mathnormal">ss</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.7778em;vertical-align:-0.0833em;"></span><span class="mord">&quot;</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">ab</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.7335em;vertical-align:-0.0391em;"></span><span class="mord mathnormal">an</span><span class="mord mathnormal">c</span><span class="var" data-var="h" data-desc="Number of parallel attention heads (h = 8)" style="--var-color: #ff7b72"><span class="mord mathnormal">h</span></span><span class="mord mathnormal" style="margin-right:0.02778em;">or</span><span class="mord">&quot;</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">&gt;&lt;</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">/</span><span class="mord mathnormal">s</span><span class="mord mathnormal">p</span><span class="mord mathnormal">an</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">&gt;</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">F</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">conf</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="var" data-var="x" data-desc="Input tensor" style="--var-color: #98c379"><span class="mord mathnormal">x</span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">c</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.4638em;vertical-align:-1.4138em;"></span><span class="mord">−</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.05em;"><span style="top:-1.8723em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.4138em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="var" data-var="x" data-desc="Input tensor" style="--var-color: #98c379"><span class="mord mathnormal">x</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">ij</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:2.3277em;vertical-align:-1.2777em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.05em;"><span style="top:-1.8723em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2777em;"><span></span></span></span></span></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:2.4638em;vertical-align:-1.4138em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.05em;"><span style="top:-1.8723em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.4138em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="var" data-var="x" data-desc="Input tensor" style="--var-color: #98c379"><span class="mord mathnormal">x</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">ij</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></div>

<p>In the above objective <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mo>∑</mo><mi>j</mi></msub><msub><mi>x</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">\sum_jx_{ij} =1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1858em;vertical-align:-0.4358em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.162em;"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4358em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="var" data-var="x" data-desc="Input tensor" style="--var-color: #98c379"><span class="mord mathnormal">x</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">ij</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1</span></span></span></span></span> iff prediction <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6595em;"></span><span class="mord mathnormal">i</span></span></span></span></span> has been matched to
a groundtruth. In that case <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>c</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">c_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span> is being maximized, while in the opposite case
it is being minimized. A different interpretation of the above term is achieved
if we <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mo>∑</mo><mi>j</mi></msub><msub><mi>x</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub></mrow><annotation encoding="application/x-tex">\sum_jx_{ij}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1858em;vertical-align:-0.4358em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.162em;"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4358em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="var" data-var="x" data-desc="Input tensor" style="--var-color: #98c379"><span class="mord mathnormal">x</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">ij</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span></span> view as a probability of prediction <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6595em;"></span><span class="mord mathnormal">i</span></span></span></span></span> containing an object of interest. Then, the
above loss is the negative of the entropy and thus corresponds to a max entropy loss.</p>

<p>The final loss objective combines the matching and confidence losses:</p>

<div class="math-display"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>F</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>l</mi><mo separator="true">,</mo><mi>c</mi><mo stretchy="false">)</mo><mo>=</mo><mi>α</mi><msub><mi>F</mi><mtext>match</mtext></msub><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>l</mi><mo stretchy="false">)</mo><mo>+</mo><msub><mi>F</mi><mtext>conf</mtext></msub><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>c</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">F(x,l,c) = \alpha F_{\text{match}}(x, l) + F_{\text{conf}}(x, c)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">F</span><span class="mopen">(</span><span class="var" data-var="x" data-desc="Input tensor" style="--var-color: #98c379"><span class="mord mathnormal">x</span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">c</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">F</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">match</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="var" data-var="x" data-desc="Input tensor" style="--var-color: #98c379"><span class="mord mathnormal">x</span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">F</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">conf</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="var" data-var="x" data-desc="Input tensor" style="--var-color: #98c379"><span class="mord mathnormal">x</span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">c</span><span class="mclose">)</span></span></span></span></span></div>

<p>subject to constraints in Eq.~<a href="#eq:assignment_objective" class="cross-ref">Eq. 1</a>. <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi></mrow><annotation encoding="application/x-tex">\alpha</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span></span></span></span></span> balances the contribution of the different loss terms.
\vspace{-0.5cm}
**Optimization.** For each training example, we solve for an optimal assignment <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>x</mi><mo>∗</mo></msup></mrow><annotation encoding="application/x-tex">x^*</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6887em;"></span><span class="mord"><span class="var" data-var="x" data-desc="Input tensor" style="--var-color: #98c379"><span class="mord mathnormal">x</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6887em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span></span></span></span></span> of predictions to
true boxes by
\begin{eqnarray}
x^*& =&\arg\min_xF(x,l,c) \\
\text{subject to } && x_{ij}\in\{0,1\}, \sum_ix_{ij} = 1,
\end{eqnarray}
where the constraints enforce an assignment solution. This is a variant of bipartite matching,
which is polynomial in complexity. In our application the matching is very inexpensive -- the number of labeled
objects per image is less than a dozen and in most cases only very few objects are labeled.</p>

<p>Then, we optimize the network parameters via back-propagation. For example,
the first derivatives of the back-propagation
algorithm are computed w. r. t.  <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>l</mi></mrow><annotation encoding="application/x-tex">l</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span></span></span></span></span> and <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>c</mi></mrow><annotation encoding="application/x-tex">c</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">c</span></span></span></span></span>:
\begin{eqnarray}
  \frac{\partial F}{\partial l_i} & =&\sum_j(l_i - g_j)x_{ij}^* \\
  \frac{\partial F}{\partial c_i} & = & \frac{\sum_jx_{ij}^*c_i}{c_i(1-c_i)}
\end{eqnarray}</p>

<p>\vspace{-0.5cm}**Training Details.** While the loss as defined above is
in principle sufficient, three
modifications make it possible to reach better accuracy significantly faster.
The first such modification is to perform clustering of ground truth locations
and find <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="var" data-var="K" data-desc="Key matrix — packed keys (shape: seq_len × d_k)" style="--var-color: #58a6ff"><span class="mord mathnormal" style="margin-right:0.07153em;">K</span></span></span></span></span></span> such clusters/centroids that we can use as priors for each of the
predicted locations. Thus, the learning algorithm is encouraged to learn a
residual to a prior, for each of the predicted locations.</p>

<p>A second modification pertains to using these priors in the matching
process: instead of
matching the <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span></span></span></span></span> ground truth locations with the <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="var" data-var="K" data-desc="Key matrix — packed keys (shape: seq_len × d_k)" style="--var-color: #58a6ff"><span class="mord mathnormal" style="margin-right:0.07153em;">K</span></span></span></span></span></span> predictions, we find the best
match between the <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="var" data-var="K" data-desc="Key matrix — packed keys (shape: seq_len × d_k)" style="--var-color: #58a6ff"><span class="mord mathnormal" style="margin-right:0.07153em;">K</span></span></span></span></span></span> priors and the ground truth. Once the matching is done, the
target confidences are computed as before. Moreover, the location prediction
loss is also unchanged: for any matched pair of (target, prediction) locations,
the loss is defined by the difference between the groundtruth and the
coordinates that correspond to the matched prior. We call the usage of priors
for matching *prior matching* and hypothesize that it enforces diversification among
the predictions.</p>

<p>It should be noted, that although we defined our method in a class-agnostic
way, we can apply it to predicting object boxes for a particular class. To do this,
we simply need to train our models on bounding boxes for that class.</p>

<p>Further, we can predict <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="var" data-var="K" data-desc="Key matrix — packed keys (shape: seq_len × d_k)" style="--var-color: #58a6ff"><span class="mord mathnormal" style="margin-right:0.07153em;">K</span></span></span></span></span></span> boxes per
class. Unfortunately, this model will have number of parameters growing
linearly with the number of classes. Also, in a typical setting, where the number of
objects for a given class is relatively small, most of these parameters will
see very few training examples with a corresponding gradient contribution. We
argue thusly that our two-step process -- first localize, then recognize -- is
a superior alternative in that it allows leveraging data from multiple object
types in the same image using a small number of parameters.</p>

<hr>

<h2>4. Experimental results</h2>

### Network Architecture and Experiment Details

<p>The network architecture for the localization and classification
models that we use is the same as the one used by~[krizhevsky2012imagenet].
We use Adagrad for controlling the learning rate decay, mini-batches of
size 128, and parallel distributed training with multiple identical replicas
of the network, which achieves faster convergence. As mentioned previously,
we use priors in the localization loss -- these are computed using <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span></span>-means
on the training set. We also use an <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi></mrow><annotation encoding="application/x-tex">\alpha</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span></span></span></span></span>
of <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0.3</mn></mrow><annotation encoding="application/x-tex">0.3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">0.3</span></span></span></span></span> to balance the localization and confidence losses.</p>

<p>The localizer might output coordinates outside the crop area used for the
inference. The coordinates are mapped and truncated to the final image area,
at the end. Boxes are additionally pruned using non-maximum-suppression with
a Jaccard similarity threshold of <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0.5</mn></mrow><annotation encoding="application/x-tex">0.5</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">0.5</span></span></span></span></span>. Our second model then classifies
each bounding box as objects of interest or ``background''.</p>

<p>To train our localizer networks, we generated approximately <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>30</mn></mrow><annotation encoding="application/x-tex">30</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">30</span></span></span></span></span> million images from the
training set, applying the following procedure to each image in the training set.
The samples are shuffled at the end.
To train our localizer networks, we generated approximately <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>30</mn></mrow><annotation encoding="application/x-tex">30</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">30</span></span></span></span></span> million images
from the training set by applying the following procedure to each image in the
training set.
For each image, we generate the same number of square samples such that the 
total number of samples is about ten million.
For each image, the samples are bucketed such that for each of the ratios in
the ranges of <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn><mo>−</mo><mn>5</mn><mi mathvariant="normal">%</mi><mo separator="true">,</mo><mn>5</mn><mo>−</mo><mn>15</mn><mi mathvariant="normal">%</mi><mo separator="true">,</mo><mn>15</mn><mo>−</mo><mn>50</mn><mi mathvariant="normal">%</mi><mo separator="true">,</mo><mn>50</mn><mo>−</mo><mn>100</mn><mi mathvariant="normal">%</mi></mrow><annotation encoding="application/x-tex">0-5\%, 5-15\%, 15-50\%, 50-100\%</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">0</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.9444em;vertical-align:-0.1944em;"></span><span class="mord">5%</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">5</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.9444em;vertical-align:-0.1944em;"></span><span class="mord">15%</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">15</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.9444em;vertical-align:-0.1944em;"></span><span class="mord">50%</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">50</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8056em;vertical-align:-0.0556em;"></span><span class="mord">100%</span></span></span></span></span>,
there is an equal number of samples in which the ratio covered by the bounding
boxes is in the given range.</p>

<p>The selection of the training set and most of our hyper-parameters were based on past
experiences with non-public data sets. For the experiments below we have not
explored any non-standard data generation or regularization options.</p>

<p>In all experiments, all hyper-parameters were selected by evaluating on a
held out portion of the training set (10\% random choice of examples).</p>

### VOC 2007

<p>The Pascal Visual Object Classes (VOC) Challenge [everingham2010pascal]
is the most commong benchmark for object detection algorithms. It consists mainly
of complex scene images in which bounding boxes of 20 diverse object classes
were labelled.</p>

<p>In our evaluation we focus on the 2007 edition of VOC, for which a test set was
released. We present results by training on VOC 2012, which contains approx. 11000 images.
We trained a <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>100</mn></mrow><annotation encoding="application/x-tex">100</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">100</span></span></span></span></span> box localizer as well as a deep net based classifier
[krizhevsky2012imagenet].</p>

#### Training methodology
We trained the classifier on a data set comprising of
- <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>10</mn></mrow><annotation encoding="application/x-tex">10</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">10</span></span></span></span></span> million crops overlapping some object with at least <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0.5</mn></mrow><annotation encoding="application/x-tex">0.5</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">0.5</span></span></span></span></span> Jaccard overlap
similarity. The crops are labeled with one of the 20 VOC object classes.
- <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>20</mn></mrow><annotation encoding="application/x-tex">20</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">20</span></span></span></span></span> million negative crops that have at most <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0.2</mn></mrow><annotation encoding="application/x-tex">0.2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">0.2</span></span></span></span></span> Jaccard similarity
with any of the object boxes. These crops are labeled with the special
``background'' class label.
The architecture and the selection of hyperparameters followed that of
[krizhevsky2012imagenet].

#### Evaluation methodology

<p>In the first round, the localizer model is applied to the maximum center
square crop in the image. The crop is resized to the network input size which is
<span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>220</mn><mo>×</mo><mn>220</mn></mrow><annotation encoding="application/x-tex">220 \times 220</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">220</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">220</span></span></span></span></span>. A single pass through this network gives us up to hundred
candidate boxes. After a non-maximum-suppression with overlap threshold <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0.5</mn></mrow><annotation encoding="application/x-tex">0.5</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">0.5</span></span></span></span></span>,
the top <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>10</mn></mrow><annotation encoding="application/x-tex">10</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">10</span></span></span></span></span> highest scoring detections are kept and were classified by the
21-way classifier model in a separate passes through the network.
The final detection score is the product of the localizer score for the given
box multiplied by the score of the classifier evaluated on the maximum square
region around the crop. These scores are passed to the evaluation and were used
for computing the precision recall curves.</p>

### Discussion

<p>First, we analyze the performance of our localizer in isolation. We present the number of detected objects,
as defined by the Pascal detection criterion,
against the number of produced bounding boxes. In Fig.~<a href="#fig:saliency" class="cross-ref">Fig. 1</a> plot we show results obtained by
training on VOC2012. In addition, we present
results by using the max-center square crop of the image as input as well as by
using two scales: the max-center crop by a second scale where we select <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3</mn><mo>×</mo><mn>3</mn></mrow><annotation encoding="application/x-tex">3\times 3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">3</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">3</span></span></span></span></span> windows
of size <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>60</mn><mi mathvariant="normal">%</mi></mrow><annotation encoding="application/x-tex">60\%</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8056em;vertical-align:-0.0556em;"></span><span class="mord">60%</span></span></span></span></span> of the image size.</p>

<p>As we can see, when using a budget of <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>10</mn></mrow><annotation encoding="application/x-tex">10</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">10</span></span></span></span></span>
bounding boxes we can localize <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>45.3</mn><mi mathvariant="normal">%</mi></mrow><annotation encoding="application/x-tex">45.3\%</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8056em;vertical-align:-0.0556em;"></span><span class="mord">45.3%</span></span></span></span></span> of the objects with the first model, and <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>48</mn><mi mathvariant="normal">%</mi></mrow><annotation encoding="application/x-tex">48\%</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8056em;vertical-align:-0.0556em;"></span><span class="mord">48%</span></span></span></span></span> with
the second model. This shows better perfomance than other reported results, such as
the objectness algorithm achieving <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>42</mn><mi mathvariant="normal">%</mi></mrow><annotation encoding="application/x-tex">42\%</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8056em;vertical-align:-0.0556em;"></span><span class="mord">42%</span></span></span></span></span> [alexe2010object]. Further, this plot
shows the importance of looking at the image at several resolutions. Although our algorithm
manages to get large number of objects by using the max-center crop, we obtain an additional boost
when using higher resolution image crops.</p>

<table class="article-table">
  <caption><span id="table:pr_voc</caption>
  <thead><tr>
    <th>class</th>
    <th>aero</th>
    <th>bicycle</th>
    <th>bird</th>
    <th>boat</th>
    <th>bottle</th>
    <th>bus</th>
    <th>car</th>
    <th>cat</th>
    <th>chair</th>
    <th>cow</th>
  </tr></thead>
  <tbody>
  <tr>
    <td>DeepMultiBox</td>
    <td>{\bf .413" class="label-anchor"></span></td>
    <td>.277</td>
    <td>{\bf .305}</td>
    <td>{\bf .176}</td>
    <td>.032</td>
    <td>.454</td>
    <td>.362</td>
    <td>{\bf .535}</td>
    <td>.069</td>
    <td>.256</td>
  </tr>
  <tr>
    <td>3-layer model [zhu2010latent]</td>
    <td>.294</td>
    <td>.558</td>
    <td>.094</td>
    <td>.143</td>
    <td>.286</td>
    <td>.440</td>
    <td>.513</td>
    <td>.213</td>
    <td>.200</td>
    <td>.193</td>
  </tr>
  <tr>
    <td>Felz. et al. [felzenszwalb2010object]</td>
    <td>.328</td>
    <td>.568</td>
    <td>.025</td>
    <td>.168</td>
    <td>{\bf .285}</td>
    <td>.397</td>
    <td>.516</td>
    <td>.213</td>
    <td>.179</td>
    <td>.185</td>
  </tr>
  <tr>
    <td>Girshick et al. [voc-release5]</td>
    <td>.324</td>
    <td>{\bf .577}</td>
    <td>.107</td>
    <td>.157</td>
    <td>.253</td>
    <td>.513</td>
    <td>{\bf .542}</td>
    <td>.179</td>
    <td>{\bf .210}</td>
    <td>.240</td>
  </tr>
  <tr>
    <td>Szegedy et al. [szegedy2013detection]</td>
    <td>.292</td>
    <td>.352</td>
    <td>.194</td>
    <td>.167</td>
    <td>.037</td>
    <td>{\bf .532}</td>
    <td>.502</td>
    <td>.272</td>
    <td>.102</td>
    <td>{\bf .348}</td>
  </tr>
  <tr>
    <td>class</td>
    <td>table</td>
    <td>dog</td>
    <td>horse</td>
    <td>m-bike</td>
    <td>person</td>
    <td>plant</td>
    <td>sheep</td>
    <td>sofa</td>
    <td>train</td>
    <td>tv</td>
  </tr>
  <tr>
    <td>DeepMultiBox</td>
    <td>.273</td>
    <td>{\bf .464}</td>
    <td>.312</td>
    <td>.297</td>
    <td>.375</td>
    <td>.074</td>
    <td>.298</td>
    <td>.211</td>
    <td>.436</td>
    <td>.225</td>
  </tr>
  <tr>
    <td>3-layer model [zhu2010latent]</td>
    <td>.252</td>
    <td>.125</td>
    <td>.504</td>
    <td>.384</td>
    <td>.366</td>
    <td>{\bf .151}</td>
    <td>.197</td>
    <td>.251</td>
    <td>.368</td>
    <td>.393</td>
  </tr>
  <tr>
    <td>Felz. et al. [felzenszwalb2010object]</td>
    <td>.259</td>
    <td>.088</td>
    <td>.492</td>
    <td>.412</td>
    <td>.368</td>
    <td>.146</td>
    <td>.162</td>
    <td>.244</td>
    <td>.392</td>
    <td>.391</td>
  </tr>
  <tr>
    <td>Girshick et al. [voc-release5]</td>
    <td>.257</td>
    <td>.116</td>
    <td>{\bf .556}</td>
    <td>{\bf .475}</td>
    <td>{\bf .435}</td>
    <td>.145</td>
    <td>.226</td>
    <td>{\bf .342}</td>
    <td>{\bf .442}</td>
    <td>.413</td>
  </tr>
  <tr>
    <td>Szegedy et al .[szegedy2013detection]</td>
    <td>{\bf .302}</td>
    <td>.282</td>
    <td>.466</td>
    <td>.417</td>
    <td>.262</td>
    <td>.103</td>
    <td>{\bf .328}</td>
    <td>.268</td>
    <td>.398</td>
    <td>{\bf .47}</td>
  </tr>
  </tbody>
</table>

<p>Further, we classify the produced bounding boxes by a 21-way classifier, as described above.
The average precisions (APs) on VOC 2007 are presented in Table~<a href="#table:pr_voc" class="cross-ref">Table 1</a>. The achieved
mean AP is <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0.29</mn></mrow><annotation encoding="application/x-tex">0.29</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">0.29</span></span></span></span></span>, which is on par with state-of-art. Note that, our running time complexity
is very low -- we simply use the top <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>10</mn></mrow><annotation encoding="application/x-tex">10</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">10</span></span></span></span></span> boxes.</p>

<p>Example detections and full precision recall curves are shown in Fig.~<a href="#fig:vocdetections" class="cross-ref">Fig. 2</a>
and Fig.~<a href="#fig:vocprecrecall" class="cross-ref">Fig. 3</a> respectively. It is important to note that the visualized detections
were obtained by using only the max-centered square image crop, i. e. the full image was used.
Nevertheless, we manage to obtain relatively small objects, such as the boats in row 2 and column 2,
as well as the sheep in row 3 and column 3.</p>

### ILSVRC 2012 Detection Challenge

<p>For this set of experiments, we used the ILSVRC 2012 detection challenge
dataset. This dataset consists of 544,545 training images labeled with
categories and locations of 1,000 object categories, relatively uniformly
distributed among the classes. The validation set, on which the performance
metrics are calculated, consists of 48,238 images.</p>

#### Training methodology

<p>In addition to a localization model that is
identical (up to the dataset on which it is trained on) to the VOC model, we
also train a model on the ImageNet Classification challenge data, which will
serve as the recognition model. This model is trained in a procedure that is
substantially similar to that of [krizhevsky2012imagenet] and is able to
achieve the same results on the classification challenge validation set; note
that we only train a single model, instead of <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>7</mn></mrow><annotation encoding="application/x-tex">7</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">7</span></span></span></span></span> -- the latter brings
substantial benefits in terms of classification accuracy, but is <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>7</mn><mo>×</mo></mrow><annotation encoding="application/x-tex">7\times</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">7</span><span class="mord">×</span></span></span></span></span> more
expensive, which is not a negligible factor.</p>

<p>Inference is done as with the VOC setup: the number of predicted locations is
<span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi><mo>=</mo><mn>100</mn></mrow><annotation encoding="application/x-tex">K=100</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="var" data-var="K" data-desc="Key matrix — packed keys (shape: seq_len × d_k)" style="--var-color: #58a6ff"><span class="mord mathnormal" style="margin-right:0.07153em;">K</span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">100</span></span></span></span></span>, which are then reduced by Non-Max-Suppression (Jaccard overlap
criterion of <span class="math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0.4</mn></mrow><annotation encoding="application/x-tex">0.4</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">0.4</span></span></span></span></span>) and which are post-scored by the classifier: the score is
the product of the localizer confidence for the given box multiplied by the
score of the classifier evaluated on the minimum square region around the crop.
The final scores (detection score times classification score) are then sorted
in descending order and only the top scoring score/location pair is kept for a
given class (as per the challenge evaluation criterion).</p>

<p>In all experiments, the hyper-parameters were selected by evaluating on a held
out portion of the training set (10\% random choice of examples).</p>

#### Evaluation methodology
The official metric of the ``Classification with localization`` ILSVRC-2012
challenge is detection@5, where an algorithm is only allowed to produce one box
per each of the 5 labels (in other words, a model is neither penalized nor
rewarded for producing valid multiple detections of the same class), where the
detection criterion is 0.5 Jaccard overlap with any of the ground-truth boxes
(in addition to the matching class label).

<p>Table~<a href="#t:imagenet_results" class="cross-ref">Table 2</a> contains a comparison of the proposed method,
dubbed DeepMultiBox, with classifying the ground-truth boxes directly and with
the approach of inferring one box per class directly. The metrics reported are
detection\@5 and classification\@5, the official metrics for the ILSVRC-2012
challenge metrics. In the table, we vary the number of windows at which we
apply the classifier (this number represents the top windows chosen after
non-max-suppression, the ranking coming from the confidence scores). The
one-box-per-class approach is a careful re-implementation of the winning entry
of ILSVRC-2012 (the ``classification with localization'' challenge), with 1
network trained (instead of 7).</p>

<table class="article-table">
  <caption>Performance of Multibox (the proposed method) vs. classifying
  ground-truth boxes directly and predicting one box per class</caption>
  <thead><tr>
    <th>\bf{Method}</th>
    <th>\bf{det@5}</th>
    <th>\bf{class@5}</th>
  </tr></thead>
  <tbody>
  <tr>
    <td>One-box-per-class</td>
    <td>61.00\%</td>
    <td>79.40\%</td>
  </tr>
  <tr>
    <td>Classify GT directly</td>
    <td>82.81\%</td>
    <td>82.81\%</td>
  </tr>
  <tr>
    <td>DeepMultiBox, top 1 window</td>
    <td>56.65\%</td>
    <td>73.03\%</td>
  </tr>
  <tr>
    <td>DeepMultiBox, top 3 windows</td>
    <td>58.71\%</td>
    <td>77.56\%</td>
  </tr>
  <tr>
    <td>DeepMultiBox, top 5 windows</td>
    <td>58.94\%</td>
    <td>78.41\%</td>
  </tr>
  <tr>
    <td>DeepMultiBox, top 10 windows</td>
    <td>59.06\%</td>
    <td>78.70\%</td>
  </tr>
  <tr>
    <td>DeepMultiBox, top 25 windows</td>
    <td>59.04\%</td>
    <td>78.76\%</td>
  </tr>
  </tbody>
</table>

<p>We can see that the DeepMultiBox approach is quite competitive: with 5-10
windows, it is able to perform about as well as the competing approach.  While
the one-box-per-class approach may come off as more appealing in this
particular case in terms of the raw performance, it suffers from a number of
drawbacks: first, its output scales linearly with the number of classes, for
which there needs to be training data. The multibox approach can in principle
use transfer learning to detect certain types of objects on which it has never
been specifically trained on, but which share similarities with objects that it
*has* seen.  Figure <a href="#fig:agnostic_transfer" class="cross-ref">Fig. 5</a> explores this hypothesis by
observing what happens when one takes a localization model trained on ImageNet
and applies it on the VOC test set, and vice-versa. The figure shows a
precision-recall curve: in this case, we perform a *class-agnostic*
detection: a true positive occurs if two windows (prediction and groundtruth)
overlap by more than 0.5, independently of their class. Interestingly, the
ImageNet-trained model is able to capture more VOC windows than vice-versa: we
hypothesize that this is due to the ImageNet class set being much richer than
the VOC class set.</p>

<p>Secondly, the one-box-per-class approach does not generalize naturally to
multiple instances of objects of the same type (except via the the method
presented in this work, for instance). Figure <a href="#fig:agnostic_transfer" class="cross-ref">Fig. 5</a> shows
this too, in the comparison between DeepMultiBox and the one-per-class
approach. Generalizing to such a scenario is necessary for
actual image understanding by algorithms, thus such limitations need to be
overcome, and our method is a scalable way of doing so.  Evidence supporting
this statement is shown in Figure <a href="#fig:agnostic_transfer" class="cross-ref">Fig. 5</a> shows that the
proposed method is able to generally capture more objects more accurately that
a single-box method.</p>

<figure id="fig:agnostic_transfer">
<img src="./figures/imagenet_agnostic.png" alt="\label{fig:agnostic_transfer" loading="lazy" style="max-width:100%">
<img src="./figures/voc_agnostic.png" alt="\label{fig:agnostic_transfer" loading="lazy" style="max-width:100%">
<figcaption><strong>Figure 5.</strong> \label{fig:agnostic_transfer</figcaption>
</figure>

<hr>

<h2>5. Discussion and Conclusion</h2>

<p>In this work, we propose a novel method for localizing objects in an image,
which predicts multiple bounding boxes at a time. The method uses a deep
convolutional neural network as a base feature extraction and learning model.
It formulates a multiple box localization cost that is able to take advantage
of variable number of groundtruth locations of interest in a given image and
learn to predict such locations in unseen images.</p>

<p>We present results on two challenging benchmarks, VOC2007 and ILSVRC-2012, on which the proposed method
is competitive. Moreover, the method is able to perform well by
predicting only very few locations to be probed by a subsequent classifier. Our
results show that the DeepMultiBox approach is scalable and can even generalize
across the two datasets, in terms of being able to predict locations of
interest, even for categories on which it was not trained on. Additionally, it is
able to capture multiple instances of objects of the same class, which is an important
feature of algorithms that aim for better image understanding.</p>

<p>In the future, we hope to be able to fold the localization and recognition
paths into a single network, such that we would be able to extract both
location and class label information in a one-shot feed-forward pass through
the network. Even in its current state, the two-pass procedure (localization
network followed by categorization network) entails 5-10 network evaluations,
each at roughly 1 CPU-sec (modern machine). Importantly, this number does
*not* scale linearly with the number of classes to be recognized, which
makes the proposed approach very competitive with DPM-like approaches.</p>

<p>{\small
\bibliographystyle{ieee}
\bibliography{multibox_arxiv}
}</p>

<hr>

<h2>References</h2>
<ol class="references">
</ol>

title: Using the Output Embedding to Improve Language Models
short_title: Using the Output Embedding to Improve Laâ€¦
type: journal-article
authors:
  - given: Ofir Press \and Lior Wolf School of Computer Science Tel-Aviv
    family: University
  - given: ''
    family: wolf\
date: '2026-03-01'
url: https://arxiv.org/abs/1608.05859
pdf: https://arxiv.org/pdf/1608.05859
arxiv_id: '1608.05859'
archive: arxiv
archive_url: https://arxiv.org/abs/1608.05859
source: arxiv-pipeline
pipeline_version: '2.0'
tags:
  - auto-imported
  - arxiv-pipeline
abstract: >-
  We study the topmost weight matrix of neural network language models. We show that this matrix
  constitutes a valid word embedding. When training language models, we recommend tying the input
  embedding and this output embedding. We analyze the resulting update rules and show that the tied
  embedding evolves in a more similar way to the output embedding than to the input embedding in the
  untied model. We also offer a new method of regularizing the output embedding. Our methods lead to
  a significant
files:
  - name: paper.html
    format: html
    description: Rendered with KaTeX math and extracted figures
    primary: true
variable_count: 0
equation_count: 2
reference_count: 0
sections: 4
figures: 0
